{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building and Trainig the Model\n",
    "\n",
    "import keras\n",
    "\n",
    "encoder_inputs = keras.Input(shape=(None, num_encoder_tokens))\n",
    "encoder = keras.layers.LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "decoder_inputs = keras.Input(shape=(None, num_decoder_tokens))\n",
    "decoder_lstm = keras.layers.LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
    "decoder_dense = keras.layers.Dense(num_decoder_tokens, activation=\"softmax\")\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "model = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "model.compile(optimizer=Adam(lr=0.01, beta_1=0.9, beta_2=0.999, decay=0.001), loss='categorical_crossentropy', metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit([encoder_input_data,decoder_input_data],decoder_target_data,\n",
    "           batch_size=batch_size,epochs=epochs,validation_split=0.2,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_eng = [' ', '!', '$', \"'\", ',', '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', '?', 'A', 'B', \n",
    "              'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', \n",
    "              'W', 'Y', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', \n",
    "              'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
    "\n",
    "tokens_spn = ['N', '\\t', 'B', 'G', '\"', 'I', 'f', 'i', 'ó', '.', ',', 'Á', 'Ó', 'E', 'í', '\\n', 'y', 'C', 'Y', 'z',\n",
    "              'p', 'q', 'A', 'u', 'l', 'ñ', '¡', 'U', 'r', 'k', 't', '?', 'h', 'n', '7', 'á', 'S', '2', ':', 'É',\n",
    "              'ü', 'v', 'V', ' ', '8', '0', 'W', 'o', 'T','¿', 'e', 'ú', 'g', '»', 'd', '!', 'P', 'H', 's', 'L',\n",
    "              'O', '«', 'b', 'c', '5', '4', 'm', \"'\", 'R', '3', 'x', 'w', 'j', 'Ú', 'J', '6', 'é', 'D', 'M',\n",
    "              'F', '1', 'a', '-', 'Q']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            [(None, None, 69)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            [(None, None, 84)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, 256), (None, 333824      input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_4 (LSTM)                   [(None, None, 256),  349184      input_5[0][0]                    \n",
      "                                                                 lstm_3[0][1]                     \n",
      "                                                                 lstm_3[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, None, 84)     21588       lstm_4[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 704,596\n",
      "Trainable params: 704,596\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "char2_int_eng = dict(((x,y) for y,x in enumerate(tokens_eng,0)))\n",
    "int2_char_eng = dict(((y,x) for y,x in enumerate(tokens_eng,0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "char2_int_spn = dict(((x,y) for y,x in enumerate(tokens_spn,0)))\n",
    "int2_char_spn = dict(((y,x) for y,x in enumerate(tokens_spn,0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us load the saved model above the same\n",
    "\n",
    "from tensorflow import keras\n",
    "model = keras.models.load_model('E2S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            [(None, None, 69)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            [(None, None, 84)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, 256), (None, 333824      input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_4 (LSTM)                   [(None, None, 256),  349184      input_5[0][0]                    \n",
      "                                                                 lstm_3[0][1]                     \n",
      "                                                                 lstm_3[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, None, 84)     21588       lstm_4[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 704,596\n",
      "Trainable params: 704,596\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decode the Sentence\n",
    "encoder_inputs = model.input[0]  # input_1\n",
    "\n",
    "encoder_outputs, state_h_enc, state_c_enc = model.layers[2].output  # lstm_1\n",
    "\n",
    "encoder_states = [state_h_enc, state_c_enc] # encoder hidden states\n",
    "\n",
    "# Encoder model required only Encoder input and ender hidden states\n",
    "encoder_model = keras.Model(encoder_inputs, encoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Predict the hidden states from encoded model for use input sequence\n",
    "\n",
    "decoder_inputs = model.input[1]\n",
    "\n",
    "decoder_state_input_h = keras.Input(shape=(256,))\n",
    "decoder_state_input_c = keras.Input(shape=(256,))\n",
    "decoder_states_inputs = [decoder_state_input_h,decoder_state_input_c]\n",
    "\n",
    "\n",
    "decoder_lstm = model.layers[3]\n",
    "decoder_outputs,decoder_state_h,decoder_state_h = decoder_lstm(decoder_inputs,initial_state=decoder_states_inputs)\n",
    "decoder_output_states = [decoder_state_h,decoder_state_h]\n",
    "\n",
    "decoder_input_states = [decoder_state_input_h,decoder_state_input_c]\n",
    "\n",
    "# Decoder Model requires decoder input and decoder hidden states as first parameter and \n",
    "# decoder output and decoder output hidden states as second parameters\n",
    "decoder_model = keras.Model([decoder_inputs] + decoder_input_states,[decoder_outputs] + decoder_output_states)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def generateEncodinForPrediction(text):\n",
    "    \n",
    "    # create array of Zero with size of Max_length_seq(time_step) and Vocab_size\n",
    "    decode_input_seq = np.zeros((16,69))\n",
    "    \n",
    "    for i,char in enumerate(text):\n",
    "        \n",
    "        # Update the char values present\n",
    "        decode_input_seq[i,char2_int_eng[char]] = 1\n",
    "        \n",
    "        \n",
    "        \n",
    "    return np.asarray([decode_input_seq]) # return the 3d converted array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0.])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_seq = generateEncodinForPrediction(\"Go.\")\n",
    "\n",
    "input_seq[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "states_value = encoder_model.predict(input_seq) # combine 'states_value' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_seq = np.zeros((1, 1, len(char2_int_spn)))\n",
    "target_seq[0, 0, char2_int_spn[\"\\t\"]] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_tokens, h, c = decoder_model.predict([target_seq] + states_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_token_index = np.argmax(output_tokens[0, -1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
