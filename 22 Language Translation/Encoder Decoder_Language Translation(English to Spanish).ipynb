{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 10000\n",
    "latent_dim = 256\n",
    "batch_size = 64  \n",
    "input_texts = []\n",
    "target_texts = []\n",
    "epochs = 100  \n",
    "input_characters = set()\n",
    "target_characters = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"spa.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    lines = f.read().split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'W', '5', 'p', 'L', 'q', ',', 'v', '7', '9', 'I', 'c', 'm', 't', 'G', 'D', '4', 'R', 'h', 'K', 'V', 'k', '?', 'M', 'E', '.', 'C', 'e', 'b', 'n', 'l', '!', 'u', 'N', 'y', 'f', 'B', 'a', 'j', 'F', 'H', 'P', '3', 'g', 'o', 'x', 'T', 'w', '1', 'z', 'd', 'Y', 'J', 's', \"'\", 'U', ':', 'Q', '6', 'O', ' ', '$', '0', 'S', 'A', 'r', 'i', '2', '8', '-'}\n",
      "\n",
      "\n",
      "{'\"', 'C', 'e', 'l', '!', 'u', 'B', 'a', 'j', '3', 'x', 'z', 'd', \"'\", 'ó', ' ', 'S', 'A', 'i', 'í', 'W', 'L', 'q', 'v', '7', 'I', 't', '\\t', 'V', '?', '.', 'n', 'N', 'F', '1', 'Á', 's', 'U', ':', 'O', 'É', '2', '8', ',', '»', '4', 'G', 'h', 'k', 'M', 'E', 'b', 'P', 'g', 'w', 'Q', 'J', 'Ú', 'r', 'ú', '-', '5', 'p', 'ü', 'é', 'á', 'c', '\\n', 'm', 'D', 'ñ', 'Ó', 'R', '¡', 'y', 'f', 'H', 'o', 'T', 'Y', '¿', '6', '«', '0'}\n"
     ]
    }
   ],
   "source": [
    "for line in lines[: min(num_samples, len(lines) - 1)]:\n",
    "    input_text, target_text, _ = line.split(\"\\t\")\n",
    "    \n",
    "    ############### A ###############\n",
    "    target_text = \"\\t\" + target_text + \"\\n\"\n",
    "    input_texts.append(input_text)\n",
    "    target_texts.append(target_text)\n",
    "    ############### B ###############\n",
    "    \n",
    "    for char in input_text:\n",
    "        if char not in input_characters:\n",
    "            input_characters.add(char)\n",
    "    for char in target_text:\n",
    "        if char not in target_characters:\n",
    "            target_characters.add(char)\n",
    "            \n",
    "print(input_characters)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(target_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No.of samples: 10000\n",
      "No.of unique input tokens: 69\n",
      "No.of unique output tokens: 84\n",
      "Maximum seq length for inputs: 16\n",
      "Maximum seq length for outputs: 78\n"
     ]
    }
   ],
   "source": [
    "input_characters = sorted(list(input_characters))\n",
    "target_characters = sorted(list(target_characters))\n",
    "num_encoder_tokens = len(input_characters) # 69\n",
    "num_decoder_tokens = len(target_characters) # 84\n",
    "max_encoder_seq_length = max([len(txt) for txt in input_texts]) #16\n",
    "max_decoder_seq_length = max([len(txt) for txt in target_texts]) # 78\n",
    "\n",
    "print(\"No.of samples:\", len(input_texts))\n",
    "print(\"No.of unique input tokens:\", num_encoder_tokens)\n",
    "print(\"No.of unique output tokens:\", num_decoder_tokens)\n",
    "print(\"Maximum seq length for inputs:\", max_encoder_seq_length)\n",
    "print(\"Maximum seq length for outputs:\", max_decoder_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' ', '!', '$', \"'\", ',', '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'Y', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
      "\n",
      "\n",
      "['\\t', '\\n', ' ', '!', '\"', \"'\", ',', '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', ':', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'Y', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '¡', '«', '»', '¿', 'Á', 'É', 'Ó', 'Ú', 'á', 'é', 'í', 'ñ', 'ó', 'ú', 'ü']\n"
     ]
    }
   ],
   "source": [
    "print(input_characters)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(target_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{' ': 0, '!': 1, '$': 2, \"'\": 3, ',': 4, '-': 5, '.': 6, '0': 7, '1': 8, '2': 9, '3': 10, '4': 11, '5': 12, '6': 13, '7': 14, '8': 15, '9': 16, ':': 17, '?': 18, 'A': 19, 'B': 20, 'C': 21, 'D': 22, 'E': 23, 'F': 24, 'G': 25, 'H': 26, 'I': 27, 'J': 28, 'K': 29, 'L': 30, 'M': 31, 'N': 32, 'O': 33, 'P': 34, 'Q': 35, 'R': 36, 'S': 37, 'T': 38, 'U': 39, 'V': 40, 'W': 41, 'Y': 42, 'a': 43, 'b': 44, 'c': 45, 'd': 46, 'e': 47, 'f': 48, 'g': 49, 'h': 50, 'i': 51, 'j': 52, 'k': 53, 'l': 54, 'm': 55, 'n': 56, 'o': 57, 'p': 58, 'q': 59, 'r': 60, 's': 61, 't': 62, 'u': 63, 'v': 64, 'w': 65, 'x': 66, 'y': 67, 'z': 68}\n",
      "\n",
      "\n",
      "{'\\t': 0, '\\n': 1, ' ': 2, '!': 3, '\"': 4, \"'\": 5, ',': 6, '-': 7, '.': 8, '0': 9, '1': 10, '2': 11, '3': 12, '4': 13, '5': 14, '6': 15, '7': 16, '8': 17, ':': 18, '?': 19, 'A': 20, 'B': 21, 'C': 22, 'D': 23, 'E': 24, 'F': 25, 'G': 26, 'H': 27, 'I': 28, 'J': 29, 'L': 30, 'M': 31, 'N': 32, 'O': 33, 'P': 34, 'Q': 35, 'R': 36, 'S': 37, 'T': 38, 'U': 39, 'V': 40, 'W': 41, 'Y': 42, 'a': 43, 'b': 44, 'c': 45, 'd': 46, 'e': 47, 'f': 48, 'g': 49, 'h': 50, 'i': 51, 'j': 52, 'k': 53, 'l': 54, 'm': 55, 'n': 56, 'o': 57, 'p': 58, 'q': 59, 'r': 60, 's': 61, 't': 62, 'u': 63, 'v': 64, 'w': 65, 'x': 66, 'y': 67, 'z': 68, '¡': 69, '«': 70, '»': 71, '¿': 72, 'Á': 73, 'É': 74, 'Ó': 75, 'Ú': 76, 'á': 77, 'é': 78, 'í': 79, 'ñ': 80, 'ó': 81, 'ú': 82, 'ü': 83}\n"
     ]
    }
   ],
   "source": [
    "input_token_index = dict([(char, i) for i, char in enumerate(input_characters)])\n",
    "target_token_index = dict([(char, i) for i, char in enumerate(target_characters)])\n",
    "\n",
    "print(input_token_index)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(target_token_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(input_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_encoder_seq_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_encoder_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_data = np.zeros(\n",
    "  (len(input_texts), max_encoder_seq_length, num_encoder_tokens), dtype=\"float32\"\n",
    ")\n",
    "\n",
    "decoder_input_data = np.zeros(\n",
    "  (len(input_texts), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\"\n",
    ")\n",
    "\n",
    "decoder_target_data = np.zeros(\n",
    "  (len(input_texts), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 16, 69)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_input_data.shape # (Samples(Input_Text),Max_seq_Length_Input_text,Features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 78, 84)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_input_data.shape # (Samples(Target_Text),Max_seq_Length_Target_text,Features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 78, 84)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_target_data.shape # (Samples(Target_Text),Max_seq_Length_Target_text,Features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
    "    for t, char in enumerate(input_text):\n",
    "        encoder_input_data[i, t, input_token_index[char]] = 1.0\n",
    "    encoder_input_data[i, t + 1 :, input_token_index[\" \"]] = 1.0\n",
    "    \n",
    "    for t, char in enumerate(target_text):\n",
    "        decoder_input_data[i, t, target_token_index[char]] = 1.0\n",
    "        if t > 0:\n",
    "            decoder_target_data[i, t - 1, target_token_index[char]] = 1.0\n",
    "    decoder_input_data[i, t + 1 :, target_token_index[\" \"]] = 1.0\n",
    "    \n",
    "    decoder_target_data[i, t:, target_token_index[\" \"]] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\insakum46\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "\n",
    "encoder_inputs = keras.Input(shape=(None, num_encoder_tokens))\n",
    "encoder = keras.layers.LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "\n",
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_inputs = keras.Input(shape=(None, num_decoder_tokens))\n",
    "decoder_lstm = keras.layers.LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
    "decoder_dense = keras.layers.Dense(num_decoder_tokens, activation=\"softmax\")\n",
    "decoder_outputs = decoder_dense(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 16, 69)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_input_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 78, 84)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_input_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 78, 84)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_target_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\insakum46\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From c:\\users\\insakum46\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      "8000/8000 [==============================] - 67s 8ms/step - loss: 0.8149 - accuracy: 0.8112 - val_loss: 0.5507 - val_accuracy: 0.8380\n",
      "Epoch 2/100\n",
      "8000/8000 [==============================] - 65s 8ms/step - loss: 0.4360 - accuracy: 0.8713 - val_loss: 0.4867 - val_accuracy: 0.8550\n",
      "Epoch 3/100\n",
      "8000/8000 [==============================] - 65s 8ms/step - loss: 0.3925 - accuracy: 0.8830 - val_loss: 0.5562 - val_accuracy: 0.8394\n",
      "Epoch 4/100\n",
      "8000/8000 [==============================] - 65s 8ms/step - loss: 0.3898 - accuracy: 0.8837 - val_loss: 0.4415 - val_accuracy: 0.8646\n",
      "Epoch 5/100\n",
      "8000/8000 [==============================] - 65s 8ms/step - loss: 0.3517 - accuracy: 0.8937 - val_loss: 0.4187 - val_accuracy: 0.8728\n",
      "Epoch 6/100\n",
      "8000/8000 [==============================] - 65s 8ms/step - loss: 0.3344 - accuracy: 0.8986 - val_loss: 0.4055 - val_accuracy: 0.8777\n",
      "Epoch 7/100\n",
      "8000/8000 [==============================] - 64s 8ms/step - loss: 0.3197 - accuracy: 0.9028 - val_loss: 0.3941 - val_accuracy: 0.8808\n",
      "Epoch 8/100\n",
      "8000/8000 [==============================] - 65s 8ms/step - loss: 0.3075 - accuracy: 0.9066 - val_loss: 0.3823 - val_accuracy: 0.8847\n",
      "Epoch 9/100\n",
      "8000/8000 [==============================] - 65s 8ms/step - loss: 0.2962 - accuracy: 0.9100 - val_loss: 0.3736 - val_accuracy: 0.8875\n",
      "Epoch 10/100\n",
      "8000/8000 [==============================] - 64s 8ms/step - loss: 0.2865 - accuracy: 0.9132 - val_loss: 0.3669 - val_accuracy: 0.8892\n",
      "Epoch 11/100\n",
      "8000/8000 [==============================] - 58s 7ms/step - loss: 0.2779 - accuracy: 0.9159 - val_loss: 0.3594 - val_accuracy: 0.8919\n",
      "Epoch 12/100\n",
      "8000/8000 [==============================] - 54s 7ms/step - loss: 0.2701 - accuracy: 0.9183 - val_loss: 0.3570 - val_accuracy: 0.8925\n",
      "Epoch 13/100\n",
      "8000/8000 [==============================] - 54s 7ms/step - loss: 0.2624 - accuracy: 0.9207 - val_loss: 0.3509 - val_accuracy: 0.8952\n",
      "Epoch 14/100\n",
      "8000/8000 [==============================] - 55s 7ms/step - loss: 0.2556 - accuracy: 0.9228 - val_loss: 0.3481 - val_accuracy: 0.8959\n",
      "Epoch 15/100\n",
      "8000/8000 [==============================] - 56s 7ms/step - loss: 0.2491 - accuracy: 0.9248 - val_loss: 0.3454 - val_accuracy: 0.8969\n",
      "Epoch 16/100\n",
      "8000/8000 [==============================] - 63s 8ms/step - loss: 0.2432 - accuracy: 0.9265 - val_loss: 0.3410 - val_accuracy: 0.8985\n",
      "Epoch 17/100\n",
      "8000/8000 [==============================] - 63s 8ms/step - loss: 0.2371 - accuracy: 0.9285 - val_loss: 0.3376 - val_accuracy: 0.8995\n",
      "Epoch 18/100\n",
      "8000/8000 [==============================] - 64s 8ms/step - loss: 0.2315 - accuracy: 0.9300 - val_loss: 0.3355 - val_accuracy: 0.9009\n",
      "Epoch 19/100\n",
      "8000/8000 [==============================] - 64s 8ms/step - loss: 0.2263 - accuracy: 0.9318 - val_loss: 0.3312 - val_accuracy: 0.9022\n",
      "Epoch 20/100\n",
      "8000/8000 [==============================] - 63s 8ms/step - loss: 0.2210 - accuracy: 0.9334 - val_loss: 0.3292 - val_accuracy: 0.9027\n",
      "Epoch 21/100\n",
      "8000/8000 [==============================] - 64s 8ms/step - loss: 0.2162 - accuracy: 0.9348 - val_loss: 0.3303 - val_accuracy: 0.9030\n",
      "Epoch 22/100\n",
      "8000/8000 [==============================] - 64s 8ms/step - loss: 0.2116 - accuracy: 0.9362 - val_loss: 0.3291 - val_accuracy: 0.9036\n",
      "Epoch 23/100\n",
      "8000/8000 [==============================] - 65s 8ms/step - loss: 0.2073 - accuracy: 0.9373 - val_loss: 0.3284 - val_accuracy: 0.9042\n",
      "Epoch 24/100\n",
      "8000/8000 [==============================] - 64s 8ms/step - loss: 0.2031 - accuracy: 0.9389 - val_loss: 0.3249 - val_accuracy: 0.9061\n",
      "Epoch 25/100\n",
      "8000/8000 [==============================] - 64s 8ms/step - loss: 0.1989 - accuracy: 0.9399 - val_loss: 0.3236 - val_accuracy: 0.9057\n",
      "Epoch 26/100\n",
      "8000/8000 [==============================] - 64s 8ms/step - loss: 0.1944 - accuracy: 0.9413 - val_loss: 0.3274 - val_accuracy: 0.9057\n",
      "Epoch 27/100\n",
      "8000/8000 [==============================] - 65s 8ms/step - loss: 0.1909 - accuracy: 0.9424 - val_loss: 0.3228 - val_accuracy: 0.9074\n",
      "Epoch 28/100\n",
      "8000/8000 [==============================] - 64s 8ms/step - loss: 0.1871 - accuracy: 0.9434 - val_loss: 0.3251 - val_accuracy: 0.9067\n",
      "Epoch 29/100\n",
      "8000/8000 [==============================] - 62s 8ms/step - loss: 0.1835 - accuracy: 0.9444 - val_loss: 0.3269 - val_accuracy: 0.9068\n",
      "Epoch 30/100\n",
      "8000/8000 [==============================] - 63s 8ms/step - loss: 0.1793 - accuracy: 0.9458 - val_loss: 0.3242 - val_accuracy: 0.9080\n",
      "Epoch 31/100\n",
      "8000/8000 [==============================] - 57s 7ms/step - loss: 0.1762 - accuracy: 0.9466 - val_loss: 0.3240 - val_accuracy: 0.9084\n",
      "Epoch 32/100\n",
      "8000/8000 [==============================] - 54s 7ms/step - loss: 0.1731 - accuracy: 0.9476 - val_loss: 0.3252 - val_accuracy: 0.9080\n",
      "Epoch 33/100\n",
      "8000/8000 [==============================] - 60s 8ms/step - loss: 0.1693 - accuracy: 0.9487 - val_loss: 0.3244 - val_accuracy: 0.9087\n",
      "Epoch 34/100\n",
      "8000/8000 [==============================] - 61s 8ms/step - loss: 0.1661 - accuracy: 0.9497 - val_loss: 0.3257 - val_accuracy: 0.9080\n",
      "Epoch 35/100\n",
      "8000/8000 [==============================] - 63s 8ms/step - loss: 0.1632 - accuracy: 0.9506 - val_loss: 0.3283 - val_accuracy: 0.9087\n",
      "Epoch 36/100\n",
      "8000/8000 [==============================] - 63s 8ms/step - loss: 0.1599 - accuracy: 0.9518 - val_loss: 0.3288 - val_accuracy: 0.9087\n",
      "Epoch 37/100\n",
      "8000/8000 [==============================] - 60s 8ms/step - loss: 0.1569 - accuracy: 0.9525 - val_loss: 0.3309 - val_accuracy: 0.9083\n",
      "Epoch 38/100\n",
      "8000/8000 [==============================] - 64s 8ms/step - loss: 0.1543 - accuracy: 0.9536 - val_loss: 0.3330 - val_accuracy: 0.9081\n",
      "Epoch 39/100\n",
      "8000/8000 [==============================] - 61s 8ms/step - loss: 0.1509 - accuracy: 0.9544 - val_loss: 0.3328 - val_accuracy: 0.9084\n",
      "Epoch 40/100\n",
      "8000/8000 [==============================] - 63s 8ms/step - loss: 0.1483 - accuracy: 0.9553 - val_loss: 0.3361 - val_accuracy: 0.9087\n",
      "Epoch 41/100\n",
      "8000/8000 [==============================] - 62s 8ms/step - loss: 0.1455 - accuracy: 0.9561 - val_loss: 0.3362 - val_accuracy: 0.9085\n",
      "Epoch 42/100\n",
      "8000/8000 [==============================] - 60s 7ms/step - loss: 0.1429 - accuracy: 0.9569 - val_loss: 0.3366 - val_accuracy: 0.9082\n",
      "Epoch 43/100\n",
      "8000/8000 [==============================] - 63s 8ms/step - loss: 0.1399 - accuracy: 0.9580 - val_loss: 0.3383 - val_accuracy: 0.9087\n",
      "Epoch 44/100\n",
      "8000/8000 [==============================] - 65s 8ms/step - loss: 0.1373 - accuracy: 0.9588 - val_loss: 0.3401 - val_accuracy: 0.9089\n",
      "Epoch 45/100\n",
      "8000/8000 [==============================] - 65s 8ms/step - loss: 0.1350 - accuracy: 0.9594 - val_loss: 0.3445 - val_accuracy: 0.9084\n",
      "Epoch 46/100\n",
      "8000/8000 [==============================] - 65s 8ms/step - loss: 0.1326 - accuracy: 0.9599 - val_loss: 0.3457 - val_accuracy: 0.9082\n",
      "Epoch 47/100\n",
      "8000/8000 [==============================] - 65s 8ms/step - loss: 0.1296 - accuracy: 0.9610 - val_loss: 0.3471 - val_accuracy: 0.9089\n",
      "Epoch 48/100\n",
      "8000/8000 [==============================] - 65s 8ms/step - loss: 0.1275 - accuracy: 0.9616 - val_loss: 0.3491 - val_accuracy: 0.9088\n",
      "Epoch 49/100\n",
      "8000/8000 [==============================] - 57s 7ms/step - loss: 0.1249 - accuracy: 0.9625 - val_loss: 0.3517 - val_accuracy: 0.9092\n",
      "Epoch 50/100\n",
      "8000/8000 [==============================] - 63s 8ms/step - loss: 0.1228 - accuracy: 0.9633 - val_loss: 0.3537 - val_accuracy: 0.9089\n",
      "Epoch 51/100\n",
      "8000/8000 [==============================] - 65s 8ms/step - loss: 0.1207 - accuracy: 0.9637 - val_loss: 0.3573 - val_accuracy: 0.9086\n",
      "Epoch 52/100\n",
      "8000/8000 [==============================] - 65s 8ms/step - loss: 0.1181 - accuracy: 0.9647 - val_loss: 0.3557 - val_accuracy: 0.9085\n",
      "Epoch 53/100\n",
      "8000/8000 [==============================] - 65s 8ms/step - loss: 0.1162 - accuracy: 0.9651 - val_loss: 0.3618 - val_accuracy: 0.9087\n",
      "Epoch 54/100\n",
      "8000/8000 [==============================] - 65s 8ms/step - loss: 0.1142 - accuracy: 0.9657 - val_loss: 0.3625 - val_accuracy: 0.9082\n",
      "Epoch 55/100\n",
      "8000/8000 [==============================] - 65s 8ms/step - loss: 0.1122 - accuracy: 0.9664 - val_loss: 0.3658 - val_accuracy: 0.9084\n",
      "Epoch 56/100\n",
      "8000/8000 [==============================] - 65s 8ms/step - loss: 0.1100 - accuracy: 0.9673 - val_loss: 0.3707 - val_accuracy: 0.9075\n",
      "Epoch 57/100\n",
      "8000/8000 [==============================] - 64s 8ms/step - loss: 0.1083 - accuracy: 0.9678 - val_loss: 0.3702 - val_accuracy: 0.9078\n",
      "Epoch 58/100\n",
      "8000/8000 [==============================] - 65s 8ms/step - loss: 0.1064 - accuracy: 0.9682 - val_loss: 0.3708 - val_accuracy: 0.9080\n",
      "Epoch 59/100\n",
      "8000/8000 [==============================] - 66s 8ms/step - loss: 0.1044 - accuracy: 0.9690 - val_loss: 0.3745 - val_accuracy: 0.9085\n",
      "Epoch 60/100\n",
      "8000/8000 [==============================] - 63s 8ms/step - loss: 0.1024 - accuracy: 0.9695 - val_loss: 0.3764 - val_accuracy: 0.9085\n",
      "Epoch 61/100\n",
      "8000/8000 [==============================] - 63s 8ms/step - loss: 0.1009 - accuracy: 0.9700 - val_loss: 0.3773 - val_accuracy: 0.9081\n",
      "Epoch 62/100\n",
      "8000/8000 [==============================] - 63s 8ms/step - loss: 0.0991 - accuracy: 0.9705 - val_loss: 0.3848 - val_accuracy: 0.9074\n",
      "Epoch 63/100\n",
      "8000/8000 [==============================] - 64s 8ms/step - loss: 0.0975 - accuracy: 0.9711 - val_loss: 0.3858 - val_accuracy: 0.9075\n",
      "Epoch 64/100\n",
      "8000/8000 [==============================] - 64s 8ms/step - loss: 0.0957 - accuracy: 0.9716 - val_loss: 0.3877 - val_accuracy: 0.9074\n",
      "Epoch 65/100\n",
      "8000/8000 [==============================] - 64s 8ms/step - loss: 0.0942 - accuracy: 0.9722 - val_loss: 0.3907 - val_accuracy: 0.9078\n",
      "Epoch 66/100\n",
      "8000/8000 [==============================] - 64s 8ms/step - loss: 0.0925 - accuracy: 0.9727 - val_loss: 0.3954 - val_accuracy: 0.9073\n",
      "Epoch 67/100\n",
      "8000/8000 [==============================] - 62s 8ms/step - loss: 0.0911 - accuracy: 0.9730 - val_loss: 0.3994 - val_accuracy: 0.9069\n",
      "Epoch 68/100\n",
      "8000/8000 [==============================] - 64s 8ms/step - loss: 0.0897 - accuracy: 0.9737 - val_loss: 0.3980 - val_accuracy: 0.9072\n",
      "Epoch 69/100\n",
      "8000/8000 [==============================] - 62s 8ms/step - loss: 0.0879 - accuracy: 0.9741 - val_loss: 0.4031 - val_accuracy: 0.9068\n",
      "Epoch 70/100\n",
      "8000/8000 [==============================] - 63s 8ms/step - loss: 0.0865 - accuracy: 0.9747 - val_loss: 0.4032 - val_accuracy: 0.9068\n",
      "Epoch 71/100\n",
      "8000/8000 [==============================] - 60s 7ms/step - loss: 0.0853 - accuracy: 0.9751 - val_loss: 0.4069 - val_accuracy: 0.9068\n",
      "Epoch 72/100\n",
      "8000/8000 [==============================] - 52s 7ms/step - loss: 0.0838 - accuracy: 0.9754 - val_loss: 0.4094 - val_accuracy: 0.9063\n",
      "Epoch 73/100\n",
      "8000/8000 [==============================] - 56s 7ms/step - loss: 0.0828 - accuracy: 0.9756 - val_loss: 0.4153 - val_accuracy: 0.9065\n",
      "Epoch 74/100\n",
      "8000/8000 [==============================] - 60s 8ms/step - loss: 0.0812 - accuracy: 0.9764 - val_loss: 0.4165 - val_accuracy: 0.9063\n",
      "Epoch 75/100\n",
      "8000/8000 [==============================] - 64s 8ms/step - loss: 0.0799 - accuracy: 0.9767 - val_loss: 0.4166 - val_accuracy: 0.9068\n",
      "Epoch 76/100\n",
      "8000/8000 [==============================] - 64s 8ms/step - loss: 0.0789 - accuracy: 0.9769 - val_loss: 0.4211 - val_accuracy: 0.9063\n",
      "Epoch 77/100\n",
      "8000/8000 [==============================] - 64s 8ms/step - loss: 0.0774 - accuracy: 0.9774 - val_loss: 0.4208 - val_accuracy: 0.9066\n",
      "Epoch 78/100\n",
      "8000/8000 [==============================] - 65s 8ms/step - loss: 0.0763 - accuracy: 0.9777 - val_loss: 0.4249 - val_accuracy: 0.9065\n",
      "Epoch 79/100\n",
      "8000/8000 [==============================] - 64s 8ms/step - loss: 0.0752 - accuracy: 0.9781 - val_loss: 0.4287 - val_accuracy: 0.9058\n",
      "Epoch 80/100\n",
      "8000/8000 [==============================] - 65s 8ms/step - loss: 0.0743 - accuracy: 0.9783 - val_loss: 0.4322 - val_accuracy: 0.9061\n",
      "Epoch 81/100\n",
      "8000/8000 [==============================] - 64s 8ms/step - loss: 0.0728 - accuracy: 0.9788 - val_loss: 0.4329 - val_accuracy: 0.9061\n",
      "Epoch 82/100\n",
      "8000/8000 [==============================] - 65s 8ms/step - loss: 0.0720 - accuracy: 0.9791 - val_loss: 0.4337 - val_accuracy: 0.9061\n",
      "Epoch 83/100\n",
      "8000/8000 [==============================] - 65s 8ms/step - loss: 0.0708 - accuracy: 0.9794 - val_loss: 0.4406 - val_accuracy: 0.9056\n",
      "Epoch 84/100\n",
      "8000/8000 [==============================] - 53s 7ms/step - loss: 0.0700 - accuracy: 0.9797 - val_loss: 0.4423 - val_accuracy: 0.9052\n",
      "Epoch 85/100\n",
      "8000/8000 [==============================] - 38s 5ms/step - loss: 0.0688 - accuracy: 0.9802 - val_loss: 0.4443 - val_accuracy: 0.9054\n",
      "Epoch 86/100\n",
      "8000/8000 [==============================] - 39s 5ms/step - loss: 0.0681 - accuracy: 0.9803 - val_loss: 0.4463 - val_accuracy: 0.9052\n",
      "Epoch 87/100\n",
      "8000/8000 [==============================] - 40s 5ms/step - loss: 0.0670 - accuracy: 0.9806 - val_loss: 0.4471 - val_accuracy: 0.9058\n",
      "Epoch 88/100\n",
      "8000/8000 [==============================] - 41s 5ms/step - loss: 0.0659 - accuracy: 0.9809 - val_loss: 0.4526 - val_accuracy: 0.9048\n",
      "Epoch 89/100\n",
      "8000/8000 [==============================] - 41s 5ms/step - loss: 0.0649 - accuracy: 0.9812 - val_loss: 0.4557 - val_accuracy: 0.9055\n",
      "Epoch 90/100\n",
      "8000/8000 [==============================] - 42s 5ms/step - loss: 0.0641 - accuracy: 0.9816 - val_loss: 0.4591 - val_accuracy: 0.9051\n",
      "Epoch 91/100\n",
      "8000/8000 [==============================] - 42s 5ms/step - loss: 0.0632 - accuracy: 0.9818 - val_loss: 0.4605 - val_accuracy: 0.9053\n",
      "Epoch 92/100\n",
      "8000/8000 [==============================] - 42s 5ms/step - loss: 0.0623 - accuracy: 0.9821 - val_loss: 0.4638 - val_accuracy: 0.9048\n",
      "Epoch 93/100\n",
      "8000/8000 [==============================] - 42s 5ms/step - loss: 0.0617 - accuracy: 0.9822 - val_loss: 0.4640 - val_accuracy: 0.9051\n",
      "Epoch 94/100\n",
      "8000/8000 [==============================] - 42s 5ms/step - loss: 0.0608 - accuracy: 0.9824 - val_loss: 0.4659 - val_accuracy: 0.9052\n",
      "Epoch 95/100\n",
      "8000/8000 [==============================] - 42s 5ms/step - loss: 0.0599 - accuracy: 0.9827 - val_loss: 0.4725 - val_accuracy: 0.9046\n",
      "Epoch 96/100\n",
      "8000/8000 [==============================] - 42s 5ms/step - loss: 0.0590 - accuracy: 0.9830 - val_loss: 0.4717 - val_accuracy: 0.9046\n",
      "Epoch 97/100\n",
      "8000/8000 [==============================] - 43s 5ms/step - loss: 0.0584 - accuracy: 0.9832 - val_loss: 0.4760 - val_accuracy: 0.9048\n",
      "Epoch 98/100\n",
      "8000/8000 [==============================] - 104s 13ms/step - loss: 0.0576 - accuracy: 0.9833 - val_loss: 0.4774 - val_accuracy: 0.9044\n",
      "Epoch 99/100\n",
      "8000/8000 [==============================] - 39s 5ms/step - loss: 0.0568 - accuracy: 0.9836 - val_loss: 0.4778 - val_accuracy: 0.9044\n",
      "Epoch 100/100\n",
      "8000/8000 [==============================] - 44s 6ms/step - loss: 0.0562 - accuracy: 0.9838 - val_loss: 0.4831 - val_accuracy: 0.9047\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x25a380e0808>"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.optimizers import Adam\n",
    "\n",
    "model = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "model.compile(optimizer=Adam(lr=0.01, beta_1=0.9, beta_2=0.999, decay=0.001), loss='categorical_crossentropy', metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit([encoder_input_data,\n",
    "           decoder_input_data],\n",
    "           decoder_target_data,\n",
    "           batch_size=3,\n",
    "           epochs=epochs,validation_split=0.2,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"E2S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "#plot_model(model, to_file='modelsummary.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decode the Sentence\n",
    "\n",
    "encoder_inputs = model.input[0]  # input_1\n",
    "encoder_outputs, state_h_enc, state_c_enc = model.layers[2].output  # lstm_1\n",
    "encoder_states = [state_h_enc, state_c_enc] # encoder hidden states\n",
    "encoder_model = keras.Model(encoder_inputs, encoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now build the model for the decoder\n",
    "\n",
    "decoder_inputs = model.input[1]  # input_2\n",
    "decoder_state_input_h = keras.Input(shape=(latent_dim,), name=\"input_3\")\n",
    "decoder_state_input_c = keras.Input(shape=(latent_dim,), name=\"input_4\")\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "decoder_lstm = model.layers[3]\n",
    "decoder_outputs, state_h_dec, state_c_dec = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)\n",
    "\n",
    "decoder_states = [state_h_dec, state_c_dec]\n",
    "decoder_dense = model.layers[4]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = keras.Model([decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create two reverse-lookup token indexes to decode the sequence to make it readable\n",
    "\n",
    "reverse_input_char_index = dict((i, char) for char, i in input_token_index.items())\n",
    "reverse_target_char_index = dict((i, char) for char, i in target_token_index.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: ' ', 1: '!', 2: '$', 3: \"'\", 4: ',', 5: '-', 6: '.', 7: '0', 8: '1', 9: '2', 10: '3', 11: '4', 12: '5', 13: '6', 14: '7', 15: '8', 16: '9', 17: ':', 18: '?', 19: 'A', 20: 'B', 21: 'C', 22: 'D', 23: 'E', 24: 'F', 25: 'G', 26: 'H', 27: 'I', 28: 'J', 29: 'K', 30: 'L', 31: 'M', 32: 'N', 33: 'O', 34: 'P', 35: 'Q', 36: 'R', 37: 'S', 38: 'T', 39: 'U', 40: 'V', 41: 'W', 42: 'Y', 43: 'a', 44: 'b', 45: 'c', 46: 'd', 47: 'e', 48: 'f', 49: 'g', 50: 'h', 51: 'i', 52: 'j', 53: 'k', 54: 'l', 55: 'm', 56: 'n', 57: 'o', 58: 'p', 59: 'q', 60: 'r', 61: 's', 62: 't', 63: 'u', 64: 'v', 65: 'w', 66: 'x', 67: 'y', 68: 'z'}\n"
     ]
    }
   ],
   "source": [
    "print(reverse_input_char_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '\\t', 1: '\\n', 2: ' ', 3: '!', 4: '\"', 5: \"'\", 6: ',', 7: '-', 8: '.', 9: '0', 10: '1', 11: '2', 12: '3', 13: '4', 14: '5', 15: '6', 16: '7', 17: '8', 18: ':', 19: '?', 20: 'A', 21: 'B', 22: 'C', 23: 'D', 24: 'E', 25: 'F', 26: 'G', 27: 'H', 28: 'I', 29: 'J', 30: 'L', 31: 'M', 32: 'N', 33: 'O', 34: 'P', 35: 'Q', 36: 'R', 37: 'S', 38: 'T', 39: 'U', 40: 'V', 41: 'W', 42: 'Y', 43: 'a', 44: 'b', 45: 'c', 46: 'd', 47: 'e', 48: 'f', 49: 'g', 50: 'h', 51: 'i', 52: 'j', 53: 'k', 54: 'l', 55: 'm', 56: 'n', 57: 'o', 58: 'p', 59: 'q', 60: 'r', 61: 's', 62: 't', 63: 'u', 64: 'v', 65: 'w', 66: 'x', 67: 'y', 68: 'z', 69: '¡', 70: '«', 71: '»', 72: '¿', 73: 'Á', 74: 'É', 75: 'Ó', 76: 'Ú', 77: 'á', 78: 'é', 79: 'í', 80: 'ñ', 81: 'ó', 82: 'ú', 83: 'ü'}\n"
     ]
    }
   ],
   "source": [
    "print(reverse_target_char_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    print('input_seq:')\n",
    "    print(input_seq)\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "    print(\"Predicted states value shape:\",states_value[0].shape)\n",
    "    print(\"Predicted states value:\")\n",
    "    print(states_value)\n",
    "    \n",
    "\n",
    "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "    target_seq[0, 0, target_token_index[\"\\t\"]] = 1.0\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = \"\"\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "        \n",
    "        print(output_tokens)\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        print(sampled_token_index)\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        print(sampled_char)\n",
    "        decoded_sentence += sampled_char\n",
    "\n",
    "        if sampled_char == \"\\n\" or len(decoded_sentence) > max_decoder_seq_length:\n",
    "            stop_condition = True\n",
    "\n",
    "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.0\n",
    "\n",
    "        states_value = [h, c]\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_seq:\n",
      "[[[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [1. 0. 0. ... 0. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]]]\n",
      "Predicted states value shape: (1, 256)\n",
      "Predicted states value:\n",
      "[array([[-1.04037926e-01, -4.05267673e-03, -2.36718237e-01,\n",
      "         6.13312781e-01, -1.61019295e-01,  2.38609910e-01,\n",
      "        -2.37695320e-04,  4.79686558e-02, -9.68596160e-01,\n",
      "         2.56890029e-01,  1.02380633e-01, -9.74036157e-01,\n",
      "         4.61636577e-04, -2.87840085e-04, -1.42543912e-02,\n",
      "         4.25163656e-04, -1.11100664e-02, -3.27027887e-01,\n",
      "         5.31973600e-01, -1.49407893e-01, -3.24678188e-03,\n",
      "        -1.38657987e-02, -7.18405783e-01,  1.11014444e-04,\n",
      "         1.96326990e-02,  9.97267067e-01, -4.18721591e-09,\n",
      "         4.31703895e-01,  9.32199419e-01, -2.00840615e-04,\n",
      "        -3.86660784e-01,  2.95235366e-01, -3.37293022e-03,\n",
      "        -4.21886504e-01, -7.72998929e-01,  4.09359902e-01,\n",
      "         9.91512179e-01, -1.03226176e-03,  1.77263487e-02,\n",
      "         2.17937529e-02,  1.11791794e-03, -1.57758892e-02,\n",
      "         6.13002456e-04, -2.50475436e-01,  9.98975456e-01,\n",
      "        -1.04853600e-01,  5.82938254e-01, -3.47137451e-04,\n",
      "         5.70898652e-01,  2.20353995e-02,  7.22276270e-01,\n",
      "         5.42159239e-03,  1.74272045e-01,  7.79848397e-01,\n",
      "        -9.90269746e-06,  1.76758494e-05, -2.92058796e-01,\n",
      "         9.98348176e-01,  9.50064421e-01, -8.87900533e-04,\n",
      "         8.84884561e-04, -3.84500325e-01, -8.23454233e-04,\n",
      "         4.16866183e-01,  7.53861200e-03,  5.37670312e-05,\n",
      "        -9.22907796e-03, -4.71553722e-06,  6.37063205e-01,\n",
      "        -5.41559566e-05,  4.78711128e-02,  2.54995972e-02,\n",
      "        -1.18740287e-03, -3.36832523e-01,  9.99938130e-01,\n",
      "        -6.72030926e-01,  7.71311224e-02,  4.71821517e-01,\n",
      "         4.23854589e-03,  3.16611528e-02, -6.12089574e-01,\n",
      "        -7.09888816e-01, -6.11504376e-01,  5.30959992e-03,\n",
      "         1.92200169e-01,  2.86123686e-04, -5.51404839e-04,\n",
      "        -9.01347306e-03, -7.54914343e-01,  2.52421759e-02,\n",
      "        -8.39612156e-04,  1.35180727e-02, -9.43118811e-01,\n",
      "         9.98057902e-01,  2.12532977e-04,  5.23632625e-04,\n",
      "        -9.62135091e-05, -8.62547159e-01, -1.32928371e-01,\n",
      "         3.99423484e-03, -9.20493484e-01,  4.62504476e-01,\n",
      "         2.76163151e-03, -9.69605986e-04, -4.39330935e-01,\n",
      "         1.21229470e-01, -8.43833294e-03, -6.18845403e-01,\n",
      "         8.56189251e-01,  4.51805711e-01, -1.97706446e-02,\n",
      "         5.28148711e-02,  9.37913120e-01, -1.77066449e-05,\n",
      "         6.53097272e-01,  9.95828748e-01,  1.07714185e-03,\n",
      "        -6.82746410e-01,  2.95721412e-01, -4.65862244e-01,\n",
      "        -8.14090483e-03,  1.19483769e-02,  3.16320956e-01,\n",
      "         1.40498551e-02,  9.80515957e-01,  9.14606035e-01,\n",
      "         3.70457828e-01,  2.88375286e-05,  4.40794826e-01,\n",
      "         1.45667982e-05, -1.68429285e-01, -5.14317453e-02,\n",
      "         3.91364144e-03,  8.19916725e-01,  2.85588205e-01,\n",
      "        -1.06550600e-04, -2.73576379e-03, -1.17915392e-01,\n",
      "        -3.82241007e-04,  1.12419417e-02, -3.46187770e-01,\n",
      "         5.32454404e-04, -9.77382898e-01, -9.40557957e-01,\n",
      "         3.98579568e-01,  9.59975366e-03,  4.77040667e-05,\n",
      "         8.19497705e-01, -4.48392630e-02, -8.90405402e-02,\n",
      "         9.62110758e-01, -9.67621863e-01, -6.33378586e-05,\n",
      "        -9.98907149e-01,  9.91307557e-01,  1.09700285e-01,\n",
      "         1.31775305e-04, -3.64455819e-01, -1.04922656e-05,\n",
      "        -4.96411294e-01,  8.37373316e-01, -1.48182746e-03,\n",
      "        -4.23151255e-03,  5.81733845e-02, -1.38812363e-02,\n",
      "         2.00683236e-01, -1.08539476e-03, -1.84720140e-02,\n",
      "         3.79812688e-01, -1.30660163e-04,  1.43554607e-05,\n",
      "        -4.54773270e-02, -1.23571455e-01,  9.94731247e-01,\n",
      "         1.73110585e-03,  6.21046066e-01, -9.91763890e-01,\n",
      "        -9.36853215e-02, -1.56467333e-02,  1.81555614e-01,\n",
      "         7.57678151e-01,  3.49277169e-01,  1.45902822e-03,\n",
      "         1.27513573e-01, -5.98631948e-02, -6.53250039e-01,\n",
      "        -1.32327422e-01, -4.18237984e-01, -5.45199752e-01,\n",
      "         4.45180714e-01,  7.95632601e-03, -4.05868530e-01,\n",
      "         9.49434638e-01,  1.09892646e-02,  9.96194720e-01,\n",
      "        -6.49545670e-01, -7.59116411e-01, -3.51745188e-02,\n",
      "         5.23142695e-01, -4.15416718e-01, -9.23997760e-01,\n",
      "        -2.34873220e-03,  3.05569661e-03, -5.86314976e-01,\n",
      "        -1.10191107e-03, -8.05237472e-01,  5.91066837e-01,\n",
      "         4.27399576e-02, -7.23513449e-03,  2.34702509e-03,\n",
      "         3.93509232e-02,  7.43735731e-02, -2.70356804e-01,\n",
      "        -1.06213624e-02, -1.47051871e-01, -5.22873370e-06,\n",
      "        -6.25172470e-05, -7.00020790e-03,  5.41161426e-05,\n",
      "        -5.37786841e-01, -1.02563798e-02, -8.37295374e-04,\n",
      "         1.63428485e-02,  5.79163373e-01,  3.31065245e-02,\n",
      "         8.40309381e-01,  1.40096039e-01,  8.36684942e-01,\n",
      "        -1.64621361e-02,  1.33180721e-02, -8.07730597e-04,\n",
      "        -2.18459627e-05,  4.18184977e-03,  1.04398653e-03,\n",
      "        -1.72815099e-02,  6.57063544e-01,  1.60009265e-02,\n",
      "         5.18330812e-01, -4.14382368e-01, -9.93680907e-04,\n",
      "         3.75413030e-01, -9.90040123e-01,  8.58159959e-01,\n",
      "        -4.01483364e-02, -3.84479761e-03, -9.81410325e-01,\n",
      "        -9.97991741e-01,  4.69184488e-01,  4.06488717e-01,\n",
      "        -4.87193465e-02,  1.10950333e-03, -3.26059684e-02,\n",
      "         1.03387833e-02,  7.05323066e-04, -9.68202055e-01,\n",
      "         8.75065289e-03]], dtype=float32), array([[-8.41474915e+00, -1.79557726e-02, -2.42270947e-01,\n",
      "         6.51801157e+00, -1.67553842e-01,  1.17593489e+01,\n",
      "        -6.42715662e-04,  1.37621202e+01, -6.46852589e+00,\n",
      "         2.22946715e+00,  1.03026308e-01, -1.06579304e+01,\n",
      "         3.95123929e-01, -6.34162803e-04, -1.12878838e+01,\n",
      "         6.74599607e-04, -1.25933588e-02, -6.52004480e-01,\n",
      "         6.14919007e-01, -1.03596764e+01, -8.74195278e-01,\n",
      "        -1.17449484e+01, -1.28858519e+01,  7.93535146e-04,\n",
      "         8.77227113e-02,  4.72837639e+00, -5.10610789e-06,\n",
      "         5.41364372e-01,  5.00782537e+00, -8.43582600e-02,\n",
      "        -1.22383623e+01,  3.04637313e-01, -9.92613360e-02,\n",
      "        -2.44770193e+00, -1.33726728e+00,  1.37461309e+01,\n",
      "         6.98514605e+00, -1.90937403e-03,  2.02187654e-02,\n",
      "         1.21580276e+01,  1.25013873e-01, -1.22778893e+01,\n",
      "         5.28646708e+00, -1.32331600e+01,  1.38842430e+01,\n",
      "        -1.24189844e+01,  7.85968721e-01, -1.39474726e+01,\n",
      "         8.30028474e-01,  2.51435172e-02,  9.22745645e-01,\n",
      "         5.28554916e-02,  2.09108973e+00,  1.26742959e+00,\n",
      "        -4.69188672e-04,  4.20493912e-03, -1.31432371e+01,\n",
      "         1.16431475e+01,  1.20573130e+01, -4.30594292e-03,\n",
      "         7.10493252e-02, -1.36097412e+01, -5.00980663e+00,\n",
      "         4.57199663e-01,  2.04583073e+00,  4.84763971e-03,\n",
      "        -2.06574249e+00, -4.72809370e-06,  1.05064416e+00,\n",
      "        -6.63986604e-04,  1.17136183e+01,  7.49780273e+00,\n",
      "        -7.42777824e-01, -1.29786806e+01,  5.56509972e+00,\n",
      "        -8.16965103e-01,  7.38845062e+00,  5.15641391e-01,\n",
      "         1.25161123e+01,  1.30416336e+01, -1.32542067e+01,\n",
      "        -1.01756639e+01, -7.21421540e-01,  8.45155537e-01,\n",
      "         2.02792913e-01,  1.30086357e-03, -1.42210066e+00,\n",
      "        -1.27396602e-02, -9.88235116e-01,  2.56392863e-02,\n",
      "        -1.26916980e-02,  5.54887247e+00, -1.37271662e+01,\n",
      "         4.04981852e+00,  5.31612255e-04,  8.54445249e-02,\n",
      "        -3.19976639e-03, -8.17092609e+00, -1.36953488e-01,\n",
      "         7.00867176e-02, -9.91761208e+00,  6.41524434e-01,\n",
      "         3.12869344e-03, -2.17244208e-01, -1.37186611e+00,\n",
      "         1.39862375e+01, -1.54658020e-01, -7.23835766e-01,\n",
      "         1.40137148e+01,  4.87237066e-01, -7.58504534e+00,\n",
      "         1.05046005e+01,  1.73057830e+00, -1.88855265e-05,\n",
      "         9.35871363e-01,  9.23874474e+00,  1.36589131e-03,\n",
      "        -9.78136241e-01,  3.07408363e-01, -5.05183816e-01,\n",
      "        -6.84879589e+00,  1.21655846e+01,  4.96765471e+00,\n",
      "         1.84768084e-02,  6.24107552e+00,  1.55574882e+00,\n",
      "         1.38570118e+01,  5.37495594e-04,  4.73632932e-01,\n",
      "         1.50642918e-05, -1.70351535e-01, -1.35923996e+01,\n",
      "         3.98428971e-03,  1.70384693e+00,  2.94798762e-01,\n",
      "        -9.04083776e-04, -1.00697975e+01, -1.34602203e+01,\n",
      "        -3.84410290e-04,  1.27657962e+00, -3.62071842e-01,\n",
      "         4.14233888e-03, -8.66089058e+00, -1.75041127e+00,\n",
      "         1.41456127e+01,  9.60090850e-03,  8.82504217e-04,\n",
      "         9.95071030e+00, -9.78025341e+00, -8.19985008e+00,\n",
      "         5.11157846e+00, -2.06782174e+00, -5.39112661e-04,\n",
      "        -4.57747221e+00,  2.73937082e+00,  5.07225943e+00,\n",
      "         4.04857448e-04, -1.34058180e+01, -1.05222352e-05,\n",
      "        -1.32240725e+01,  1.35165339e+01, -1.60821399e-03,\n",
      "        -1.06369953e+01,  1.05495858e+00, -9.84960747e+00,\n",
      "         1.12623148e+01, -1.24338048e-03, -1.86593737e-02,\n",
      "         3.64495587e+00, -4.21576959e-04,  6.59435696e-04,\n",
      "        -8.65267658e+00, -1.74484432e-01,  3.22003341e+00,\n",
      "         1.08245581e-01,  5.85966778e+00, -2.74909210e+00,\n",
      "        -9.41644385e-02, -1.56504549e-02,  2.14384466e-01,\n",
      "         3.53583288e+00,  5.16588593e+00,  1.32242236e-02,\n",
      "         1.29492015e-01, -6.01038374e-02, -3.98486257e+00,\n",
      "        -1.33266538e-01, -6.69236541e-01, -6.11625731e-01,\n",
      "         1.40949211e+01,  1.50548816e-02, -1.36226435e+01,\n",
      "         1.21981459e+01,  1.10149719e-02,  1.34907742e+01,\n",
      "        -7.80965924e-01, -1.41028099e+01, -1.25690132e-01,\n",
      "         9.17929459e+00, -4.49272960e-01, -9.61053848e+00,\n",
      "        -3.85550070e+00,  3.17733712e-03, -6.76459074e-01,\n",
      "        -9.71214008e+00, -5.76078987e+00,  1.65472662e+00,\n",
      "         1.11043282e+01, -7.41259003e+00,  2.40368233e-03,\n",
      "         3.74160671e+00,  1.33655653e+01, -7.84315109e+00,\n",
      "        -6.76424354e-02, -9.72951794e+00, -2.34598108e-02,\n",
      "        -6.67404267e-04, -1.23422375e+01,  3.30578871e-02,\n",
      "        -1.38303947e+01, -1.17686672e+01, -9.28573310e-04,\n",
      "         1.63445342e-02,  2.58354855e+00,  2.79374623e+00,\n",
      "         1.31282864e+01,  1.32553701e+01,  1.23366332e+00,\n",
      "        -1.96254754e+00,  1.35166384e-02, -5.42095995e+00,\n",
      "        -9.91523173e-03,  4.45900857e-03,  2.52313842e-03,\n",
      "        -1.82776861e-02,  7.88522363e-01,  1.06169386e+01,\n",
      "         5.75167656e-01, -4.57460701e-01, -3.28074306e-01,\n",
      "         1.37350330e+01, -1.40145693e+01,  1.42929726e+01,\n",
      "        -1.01656936e-01, -1.36889420e+01, -6.50307178e+00,\n",
      "        -7.91551018e+00,  5.17829239e-01,  1.38893785e+01,\n",
      "        -1.27325706e+01,  1.12963875e-03, -3.26184630e-02,\n",
      "         1.03162088e+01,  1.30324508e-03, -1.18222504e+01,\n",
      "         4.86590773e-01]], dtype=float32)]\n",
      "[[[5.6368583e-07 1.4656300e-06 2.1094006e-06 7.2482087e-09 8.8859146e-08\n",
      "   9.1563197e-06 2.8925549e-05 2.1302259e-07 5.4265852e-06 9.6039014e-07\n",
      "   5.5911387e-06 1.9076610e-06 7.8549766e-07 5.5555881e-07 3.2557416e-06\n",
      "   1.5991276e-07 2.9089261e-07 3.3657404e-06 3.6359774e-07 4.7202935e-05\n",
      "   2.5801355e-02 6.2958472e-03 1.8721096e-02 1.1549528e-02 1.7394328e-02\n",
      "   2.1980668e-05 3.7930833e-05 4.1010664e-03 4.0158559e-02 1.7902644e-04\n",
      "   8.8272104e-03 8.5587142e-04 1.8742288e-07 4.3960795e-04 1.7483669e-03\n",
      "   8.2690363e-05 1.0277589e-03 3.3998354e-03 8.1724074e-04 2.0281498e-04\n",
      "   8.3683616e-01 4.1700423e-06 6.7302673e-05 2.5177913e-04 1.5288902e-07\n",
      "   7.0741857e-10 7.8372310e-08 6.8818792e-07 3.5471949e-08 3.1638894e-08\n",
      "   4.0229716e-07 1.1216819e-03 3.2221468e-08 8.1407512e-07 1.1155274e-08\n",
      "   5.6335097e-09 7.0299370e-07 1.0497455e-08 4.9070947e-10 1.3880184e-08\n",
      "   3.3328397e-05 2.2730745e-05 3.4451275e-09 6.2085647e-08 1.4211038e-06\n",
      "   5.8506765e-07 1.9887633e-05 3.8876887e-08 2.4149168e-07 1.5921878e-02\n",
      "   5.4194197e-07 2.1593578e-06 9.8648015e-06 1.2247363e-03 2.6762974e-04\n",
      "   1.0937041e-03 2.1418517e-05 6.4816762e-04 1.1086535e-05 5.2198389e-04\n",
      "   4.1377721e-10 4.3280975e-06 1.3417516e-04 1.3007295e-06]]]\n",
      "40\n",
      "V\n",
      "[[[4.54762539e-09 4.14293686e-12 2.27258878e-09 1.18701598e-13\n",
      "   7.23075627e-11 7.78609746e-08 5.00027326e-08 7.40000172e-10\n",
      "   3.87151144e-11 1.78256820e-09 7.49149187e-09 5.56438007e-09\n",
      "   1.37106948e-08 7.02743730e-09 7.38475379e-08 1.61174063e-09\n",
      "   3.48818907e-09 1.23421504e-08 2.02510382e-08 5.96379239e-12\n",
      "   3.30969584e-07 3.30979666e-09 5.24587129e-08 2.72268153e-07\n",
      "   6.47602583e-10 6.32480235e-10 1.50411938e-09 8.28622646e-08\n",
      "   6.21312068e-08 3.03147424e-10 1.85424671e-08 3.02480319e-10\n",
      "   4.59010364e-11 7.11749371e-09 1.31150415e-08 5.15252552e-09\n",
      "   1.45327561e-09 3.64888962e-07 1.46295032e-10 3.64110075e-10\n",
      "   6.09854833e-09 1.83057605e-08 3.32731211e-08 2.44260103e-01\n",
      "   7.64359154e-09 1.24714850e-10 1.03808732e-11 4.72556472e-01\n",
      "   5.38065983e-08 6.87325761e-12 4.27459096e-10 2.35666212e-05\n",
      "   7.64960006e-09 3.25427818e-09 4.00238565e-10 6.18674903e-12\n",
      "   1.71984327e-09 2.82426309e-02 5.00561615e-12 1.01340976e-11\n",
      "   1.38610448e-08 5.66694018e-11 1.72236780e-09 9.50467347e-06\n",
      "   9.53205426e-09 7.47911333e-09 5.70017977e-10 2.59753506e-07\n",
      "   2.63347157e-08 2.29296915e-10 5.97499383e-09 2.84634840e-08\n",
      "   3.57419150e-10 3.73923920e-10 1.77812309e-09 4.79755499e-07\n",
      "   7.59590335e-10 2.54369706e-01 4.89719969e-04 3.06348848e-05\n",
      "   3.13917087e-11 1.31143233e-05 2.02769365e-06 1.92997707e-08]]]\n",
      "47\n",
      "e\n",
      "[[[1.71294431e-07 1.67211933e-08 1.00142114e-01 2.29050329e-07\n",
      "   2.63170712e-08 5.33395834e-08 4.20706533e-03 6.07201173e-07\n",
      "   1.81606963e-01 1.57037334e-08 9.78487602e-09 1.66939557e-07\n",
      "   2.08640714e-08 3.42472418e-07 1.74869842e-06 4.55338736e-08\n",
      "   3.81856502e-08 8.36115987e-07 1.12498822e-06 9.99369377e-07\n",
      "   3.66844724e-05 3.25491527e-07 3.13158444e-06 1.35726936e-04\n",
      "   3.17139461e-06 6.99433969e-08 2.67558477e-07 9.05311367e-07\n",
      "   1.06112238e-05 9.11698947e-08 1.78478433e-06 2.66964495e-08\n",
      "   4.16390407e-08 1.79350409e-05 8.21872309e-05 6.38865401e-07\n",
      "   3.95469186e-07 6.71678254e-06 4.78554218e-09 2.97240987e-08\n",
      "   6.22198650e-06 5.53224710e-09 3.91721215e-07 1.30821741e-03\n",
      "   1.07198126e-07 5.87034665e-05 1.08552804e-07 1.92114298e-04\n",
      "   6.93329412e-08 2.62924864e-08 2.52315604e-05 1.91057325e-06\n",
      "   3.19610672e-06 1.28030877e-06 1.70645435e-04 1.47230381e-07\n",
      "   2.11694883e-03 1.16602905e-06 6.53503207e-07 6.37342552e-08\n",
      "   2.69294242e-06 3.73532530e-03 6.97258651e-01 4.18400925e-10\n",
      "   9.79581964e-04 2.05735901e-07 8.07923971e-06 3.89141869e-03\n",
      "   7.90395192e-04 5.60138460e-07 2.79222121e-07 1.20674230e-07\n",
      "   9.28881221e-08 3.69126866e-07 3.79020207e-07 1.24327869e-06\n",
      "   6.11209373e-07 2.71533360e-03 1.64326561e-08 8.76825579e-05\n",
      "   3.76433833e-04 5.93933720e-08 2.44038212e-09 8.08750666e-09]]]\n",
      "62\n",
      "t\n",
      "[[[1.27023614e-10 1.08188528e-10 1.55724031e-10 2.03208286e-13\n",
      "   1.14459253e-09 4.43166559e-10 1.21385165e-06 1.83734208e-11\n",
      "   2.00620835e-08 7.56800386e-11 2.25071753e-10 3.43126000e-10\n",
      "   1.20818833e-09 9.60739266e-11 5.23317500e-10 1.11662554e-11\n",
      "   1.23660554e-10 4.22007318e-09 2.34914033e-11 2.82844199e-11\n",
      "   2.16558926e-09 1.29282349e-10 3.59221264e-11 1.02854205e-08\n",
      "   5.45798073e-10 1.50421420e-09 8.19116164e-11 4.66585259e-09\n",
      "   5.53661117e-09 1.39415576e-10 5.91207222e-11 3.81338211e-10\n",
      "   2.87019557e-11 2.10510623e-10 1.67900147e-08 1.76667250e-10\n",
      "   3.54845250e-11 2.14683160e-09 1.04387115e-11 1.95480368e-11\n",
      "   8.27379658e-12 3.23073235e-10 1.18336580e-12 1.83741879e-02\n",
      "   2.65449973e-09 1.05763150e-11 8.39719294e-10 9.77028430e-01\n",
      "   1.09759490e-09 2.14796500e-10 2.34923109e-10 6.72534807e-05\n",
      "   2.49704035e-10 2.81831919e-10 7.02391745e-08 1.50115823e-10\n",
      "   2.88820384e-10 8.25507129e-08 9.79310428e-08 4.08169783e-11\n",
      "   4.43396857e-03 9.12230578e-13 6.09426181e-08 3.93777289e-10\n",
      "   6.98339193e-07 6.11684453e-11 9.16111913e-13 9.20895673e-07\n",
      "   1.45083147e-11 1.85397281e-10 3.21046106e-10 3.69495901e-09\n",
      "   9.44957668e-10 2.71766429e-11 9.93221755e-11 4.50405442e-11\n",
      "   5.44761181e-10 5.36707194e-05 1.89332889e-06 3.73749499e-05\n",
      "   3.03260056e-11 1.68801488e-08 5.33562927e-09 1.91118517e-08]]]\n",
      "47\n",
      "e\n",
      "[[[5.6712976e-12 6.5053828e-06 7.7749428e-04 1.4241627e-08 1.3453361e-12\n",
      "   3.5073661e-12 1.0655858e-03 4.2063317e-10 9.9813265e-01 8.8148612e-12\n",
      "   3.7988845e-11 3.5937628e-11 1.8584337e-11 1.6127577e-11 1.8443158e-11\n",
      "   1.2904946e-12 3.8468180e-11 1.4845304e-10 3.0623039e-11 1.6349260e-05\n",
      "   8.0122291e-11 1.5456766e-10 6.8260106e-11 8.2615725e-10 3.4656747e-10\n",
      "   6.0610204e-11 2.6706781e-11 3.0409399e-09 6.3609035e-11 9.5058648e-12\n",
      "   1.2766361e-11 1.8678775e-13 3.5112368e-11 3.2646419e-10 8.4224128e-10\n",
      "   1.5585408e-12 8.7480190e-11 2.1805685e-10 1.8726022e-11 7.5729197e-14\n",
      "   1.4425397e-12 6.6927854e-14 5.1550143e-13 4.8868327e-07 2.2020805e-14\n",
      "   5.3795228e-12 1.7134587e-10 1.8212999e-11 1.7616704e-13 2.6699625e-13\n",
      "   1.1962883e-12 1.3509265e-08 2.1669774e-10 5.3458741e-11 2.0871255e-07\n",
      "   3.5111391e-13 2.3287741e-09 4.3294934e-11 3.7264167e-11 3.3477898e-10\n",
      "   3.2937630e-10 1.2246401e-10 6.5860877e-09 2.0027298e-12 1.1452465e-08\n",
      "   8.5767018e-12 7.1128281e-13 5.7907079e-07 7.8862700e-10 1.9140953e-10\n",
      "   2.3619583e-12 1.0702439e-11 7.3544268e-11 5.8917787e-11 4.1499346e-10\n",
      "   4.3241348e-12 6.6659178e-10 2.3834867e-08 2.8158944e-12 1.7853651e-10\n",
      "   8.6376500e-10 8.9263835e-10 4.7376547e-11 9.0182251e-11]]]\n",
      "8\n",
      ".\n",
      "[[[1.2274448e-12 9.9994838e-01 1.3219699e-08 1.4990691e-11 1.5278157e-12\n",
      "   3.0875427e-13 2.8180812e-06 6.4625471e-12 4.6191675e-05 2.0261670e-12\n",
      "   3.5315148e-10 7.1484771e-12 6.8804189e-09 7.1448750e-13 3.2858464e-12\n",
      "   5.7890738e-14 3.1578663e-11 5.8981266e-12 1.4859308e-12 2.3926736e-08\n",
      "   1.4331772e-11 3.0636556e-13 1.2464205e-11 5.8524951e-12 1.1996459e-10\n",
      "   3.5230879e-12 2.0334220e-12 3.5299137e-09 2.8985572e-14 1.2507352e-12\n",
      "   2.2744857e-12 8.2929479e-12 4.6039058e-11 6.0866703e-14 6.8213326e-12\n",
      "   2.9930529e-12 1.8614965e-13 1.4817033e-11 3.9911179e-11 3.0401026e-14\n",
      "   7.7001007e-14 5.3955880e-14 8.6423937e-14 2.1062376e-06 2.1004391e-13\n",
      "   7.1960088e-10 3.6408662e-10 7.5562223e-11 2.2085214e-09 8.7755156e-13\n",
      "   1.2367174e-09 1.5308020e-09 3.1734747e-11 3.7759334e-11 1.2121803e-08\n",
      "   1.9819441e-11 1.3476293e-12 4.4944846e-12 9.6890100e-11 8.0640480e-11\n",
      "   1.5577352e-12 5.2748387e-12 9.5157455e-09 1.1382732e-08 1.0981929e-11\n",
      "   9.5608450e-13 7.6117964e-15 3.1080344e-07 1.0654486e-12 8.3589830e-11\n",
      "   9.6319491e-14 6.2266669e-13 2.0088804e-09 1.6293622e-13 2.9230625e-11\n",
      "   2.0129918e-13 2.0755387e-11 1.8781176e-11 2.7377510e-12 4.1627565e-12\n",
      "   3.9340666e-13 4.2738114e-13 2.1324048e-10 1.0531729e-11]]]\n",
      "1\n",
      "\n",
      "\n",
      "-\n",
      "Input: Go.\n",
      "Translation: Vete.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#i = np.random.choice(len(input_texts))\n",
    "\n",
    "\n",
    "input_seq = encoder_input_data[i:i+1]\n",
    "translation = decode_sequence(input_seq)\n",
    "print('-')\n",
    "print('Input:', input_texts[i])\n",
    "print('Translation:', translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]], dtype=float32)"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-8.65997255e-01, -1.64083466e-01, -1.76009089e-01,\n",
       "          5.79825044e-01,  1.59735009e-01,  6.97121501e-01,\n",
       "         -4.42345081e-05,  2.74505198e-01, -9.34010804e-01,\n",
       "          8.00207734e-01,  4.95174080e-02, -5.22061825e-01,\n",
       "          8.51509321e-05, -2.08945101e-04, -2.13983655e-02,\n",
       "          6.32351905e-04, -3.03273648e-02, -9.36433136e-01,\n",
       "         -2.24891633e-01, -4.97152619e-02, -4.46590036e-03,\n",
       "         -1.63370669e-02, -1.00597292e-01,  2.18334681e-05,\n",
       "          3.06617349e-01,  9.98623669e-01, -1.57105760e-08,\n",
       "         -2.04298332e-01,  7.96407342e-01, -6.92792761e-04,\n",
       "         -4.36697870e-01,  1.89555492e-02,  1.88346226e-02,\n",
       "         -4.89849925e-01, -5.03361583e-01,  2.32205003e-01,\n",
       "          1.09100647e-01, -3.76918833e-05,  4.80260860e-05,\n",
       "          9.20531154e-02,  2.69680610e-03, -3.10006738e-03,\n",
       "          1.12479925e-03, -9.75897014e-02,  9.99702871e-01,\n",
       "         -2.41952538e-02,  7.16429770e-01, -1.69187784e-04,\n",
       "          8.95674288e-01,  4.03081439e-03, -2.38570943e-01,\n",
       "          2.32321769e-03,  5.70056558e-01,  7.93615222e-01,\n",
       "         -4.17965457e-05,  8.39292534e-06, -1.57149911e-01,\n",
       "          9.96784627e-01,  7.55107760e-01, -1.50472493e-04,\n",
       "          1.37287227e-03, -8.10112476e-01, -3.00914049e-04,\n",
       "          4.78038400e-01,  3.20384443e-01,  1.85213539e-05,\n",
       "         -2.63798326e-01, -9.08302667e-04,  7.40056217e-01,\n",
       "         -3.20250583e-05,  1.40126973e-01,  2.57587433e-03,\n",
       "         -2.98067573e-02, -2.03312159e-01, -9.99270737e-01,\n",
       "         -6.91592157e-01,  5.03141284e-01,  7.81317502e-02,\n",
       "          2.60174274e-03,  2.95996666e-03, -3.30818594e-01,\n",
       "         -8.13009262e-01, -8.78329396e-01,  5.07122986e-02,\n",
       "          6.61552787e-01,  4.71117601e-05, -2.97618273e-04,\n",
       "          2.48518243e-01, -3.96756709e-01,  5.03412783e-01,\n",
       "         -1.61730262e-04,  3.53994034e-02, -1.11128151e-01,\n",
       "          2.23230392e-01,  4.63870441e-04,  1.27311982e-03,\n",
       "         -2.63192020e-02, -8.68039131e-01, -9.63146091e-01,\n",
       "          1.82395458e-01, -9.78655577e-01,  2.44763307e-02,\n",
       "          2.38255225e-03,  1.17217742e-01, -4.11459178e-01,\n",
       "          7.27242306e-02, -9.99581767e-04, -5.18369582e-03,\n",
       "          1.99814111e-01, -8.83876622e-01, -8.39905918e-01,\n",
       "          3.82578373e-03,  9.99552429e-01, -2.11211416e-04,\n",
       "          8.77016246e-01,  9.40273941e-01,  6.36388035e-03,\n",
       "         -1.15113027e-01,  3.58130932e-01,  6.56292140e-01,\n",
       "         -1.32299932e-02,  1.19438767e-03,  8.06709051e-01,\n",
       "          6.77392483e-01,  9.88161087e-01, -9.85806823e-01,\n",
       "          1.04897469e-01,  8.75194382e-06, -1.37019500e-01,\n",
       "          3.23503016e-04, -2.06567487e-03, -2.71211565e-02,\n",
       "          6.37085795e-01,  6.12461686e-01,  1.69437786e-03,\n",
       "         -4.44829017e-01, -3.61758471e-03, -5.06698191e-02,\n",
       "         -4.77602560e-04,  1.29658386e-01,  4.42729920e-01,\n",
       "          5.80350606e-05, -8.93392682e-01, -1.54574975e-01,\n",
       "          6.75874591e-01,  1.85410585e-02,  1.02474958e-04,\n",
       "          5.07037520e-01, -9.35868382e-01, -2.88467228e-01,\n",
       "          8.41525733e-01, -9.79938686e-01, -1.32262663e-04,\n",
       "         -9.80469823e-01,  9.97375727e-01,  9.11819398e-01,\n",
       "          4.89014274e-05, -1.68432951e-01, -5.43171540e-03,\n",
       "         -2.21277535e-01,  6.86157703e-01, -4.78490954e-04,\n",
       "         -2.52568722e-03,  5.88397793e-02, -6.37445450e-02,\n",
       "          3.14079702e-01, -2.29341487e-04,  4.66690540e-01,\n",
       "          5.12322664e-01, -1.32918121e-05,  4.17873671e-05,\n",
       "         -2.75261942e-02, -4.24504340e-01,  8.93941045e-01,\n",
       "          2.03877018e-04,  4.50672626e-01,  2.55613774e-01,\n",
       "          6.17247410e-02,  4.90690589e-01, -9.48188186e-01,\n",
       "          7.06260562e-01,  7.36432254e-01,  3.65402311e-01,\n",
       "          7.76535496e-02, -3.61677110e-01, -8.96844685e-01,\n",
       "         -5.53049505e-01, -5.98072670e-02,  9.99512196e-01,\n",
       "          5.84572315e-01,  8.53248537e-02, -6.55307412e-01,\n",
       "          9.72100616e-01,  1.59094576e-02,  9.95972514e-01,\n",
       "          8.33824992e-01, -7.83497751e-01, -2.97907437e-03,\n",
       "          1.06591955e-01, -9.78455171e-02, -8.69780600e-01,\n",
       "         -1.42586231e-03,  1.06160913e-03, -8.25536072e-01,\n",
       "         -1.87069178e-04, -4.55649465e-01,  7.37405658e-01,\n",
       "          2.92504311e-01, -4.02614474e-03,  4.16442403e-04,\n",
       "          1.08612776e-02,  7.26079941e-03, -2.09314693e-02,\n",
       "          9.53486338e-02, -9.78990078e-01, -2.36723245e-05,\n",
       "         -7.51049447e-06, -2.11841762e-02,  2.63746606e-05,\n",
       "         -8.57369065e-01, -9.78547335e-03, -2.22466784e-04,\n",
       "          8.51689186e-03,  7.77071059e-01,  7.31781542e-01,\n",
       "          9.43369150e-01,  4.97665256e-01,  5.41768856e-02,\n",
       "         -7.91007187e-03,  4.23578965e-03, -5.35516068e-04,\n",
       "         -1.28624786e-04,  5.13715320e-04,  9.59164317e-05,\n",
       "         -1.28157262e-03, -8.18552375e-01,  5.03708888e-03,\n",
       "          4.83603507e-01,  6.15330553e-03, -3.20342679e-07,\n",
       "          3.26697201e-01, -9.89977717e-01,  8.76531899e-01,\n",
       "         -1.68614630e-02, -2.24027038e-03, -9.62942615e-02,\n",
       "         -9.97151852e-01, -9.94136512e-01,  8.33298326e-01,\n",
       "         -7.35244155e-03,  4.32989706e-04,  6.10124059e-02,\n",
       "          3.85690629e-02,  2.93670542e-04, -9.63695288e-01,\n",
       "          2.15874449e-03]], dtype=float32),\n",
       " array([[-8.85048580e+00, -6.04358435e-01, -1.78207800e-01,\n",
       "          7.06792450e+00,  1.61650822e-01,  3.98991823e+00,\n",
       "         -1.13454742e-04,  1.21144743e+01, -6.94212008e+00,\n",
       "          1.50544763e+00,  5.00429384e-02, -5.85510910e-01,\n",
       "          1.53280810e-01, -1.28541677e-03, -1.24381552e+01,\n",
       "          1.06963760e-03, -3.11650038e-02, -8.03705025e+00,\n",
       "         -2.29725808e-01, -4.48586226e+00, -9.87581670e-01,\n",
       "         -9.22867966e+00, -1.13200836e+01,  2.82877270e-04,\n",
       "          3.36886317e-01,  6.39570856e+00, -1.75048808e-05,\n",
       "         -5.13409853e-01,  8.58237648e+00, -1.62892789e-01,\n",
       "         -9.63767052e+00,  1.89818330e-02,  5.96361518e-01,\n",
       "         -1.36535382e+00, -1.04148698e+00,  1.21275330e+01,\n",
       "          1.10947281e-01, -2.50052777e-04,  7.61586198e-05,\n",
       "          1.17988005e+01,  9.99867141e-01, -1.11673002e+01,\n",
       "          8.09699821e+00, -1.27752094e+01,  1.26618853e+01,\n",
       "         -1.20610590e+01,  9.59307432e-01, -1.30338097e+01,\n",
       "          4.70850515e+00,  6.45001745e-03, -2.55703479e-01,\n",
       "          9.96487588e-02,  2.28326416e+00,  1.26069868e+00,\n",
       "         -2.37088208e-03,  2.96445983e-03, -1.06703701e+01,\n",
       "          6.71689129e+00,  8.46685505e+00, -2.95973080e-03,\n",
       "          1.66778237e-01, -1.20077610e+01, -1.11786413e+01,\n",
       "          5.46099663e-01,  4.69296408e+00,  3.62664461e-03,\n",
       "         -3.41236782e+00, -9.10852163e-04,  2.87679434e+00,\n",
       "         -4.75398585e-04,  1.19960241e+01,  1.10941257e+01,\n",
       "         -7.38882363e-01, -1.19389277e+01, -4.31375122e+00,\n",
       "         -8.52104425e-01,  1.07987051e+01,  7.90117010e-02,\n",
       "          1.07976828e+01,  1.26242809e+01, -1.35805397e+01,\n",
       "         -1.21477833e+01, -1.37669623e+00,  1.49046040e+00,\n",
       "          1.14459586e+00,  4.79769282e-04, -1.42756522e+00,\n",
       "          5.24887264e-01, -4.21804816e-01,  5.59896350e-01,\n",
       "         -4.30434104e-03,  4.63866949e+00, -1.10278635e+01,\n",
       "          2.27328762e-01,  1.44737633e-03,  4.58483964e-01,\n",
       "         -1.46159351e-01, -3.84700251e+00, -6.55999517e+00,\n",
       "          6.27907753e-01, -8.26007557e+00,  7.40659773e-01,\n",
       "          2.48419214e-03,  7.95307159e-01, -4.99781311e-01,\n",
       "          6.14073038e+00, -2.56719496e-02, -5.19123906e-03,\n",
       "          1.15537872e+01, -1.39695621e+00, -1.04356756e+01,\n",
       "          1.01780739e+01,  4.84720564e+00, -2.17445995e-04,\n",
       "          1.45797813e+00,  6.76731348e+00,  1.27913374e-02,\n",
       "         -1.26006186e-01,  3.75676304e-01,  7.92320013e-01,\n",
       "         -8.25684261e+00,  1.16755123e+01,  1.16383696e+00,\n",
       "          8.26251745e-01,  9.87720490e+00, -2.47447062e+00,\n",
       "          1.27577620e+01,  3.67859844e-04, -1.39009729e-01,\n",
       "          3.27473972e-04, -2.08541960e-03, -1.20609598e+01,\n",
       "          8.39776993e-01,  7.50803757e+00,  1.70402951e-03,\n",
       "         -1.48829401e+00, -1.00175333e+01, -1.21226349e+01,\n",
       "         -5.22486051e-04,  7.89550245e-01,  4.75941539e-01,\n",
       "          9.25025495e-04, -8.42239475e+00, -1.56287491e-01,\n",
       "          1.14080582e+01,  1.85706038e-02,  5.13413572e-04,\n",
       "          9.37562943e+00, -9.47407246e+00, -5.96024323e+00,\n",
       "          4.03426361e+00, -2.31740499e+00, -1.12711987e-03,\n",
       "         -2.32492304e+00,  3.43310761e+00,  9.19969368e+00,\n",
       "          2.96339625e-04, -1.24682207e+01, -5.46499947e-03,\n",
       "         -9.11187553e+00,  1.28755836e+01, -5.66132017e-04,\n",
       "         -1.02870731e+01,  1.09897721e+00, -9.68227005e+00,\n",
       "          1.08517475e+01, -3.67142551e-04,  5.19711137e-01,\n",
       "          8.54168892e+00, -9.43681443e-05,  3.75175406e-03,\n",
       "         -8.75788403e+00, -4.67640549e-01,  1.44269073e+00,\n",
       "          9.42853317e-02,  1.05574989e+01,  2.61638314e-01,\n",
       "          6.19242638e-02,  5.37099957e-01, -4.85055208e+00,\n",
       "          1.45111644e+00,  8.93832970e+00,  4.13990915e-01,\n",
       "          7.85079300e-02, -3.98238778e-01, -2.94363117e+00,\n",
       "         -6.23523116e-01, -6.00447282e-02,  4.35644341e+00,\n",
       "          1.32070274e+01,  1.55932322e-01, -1.29658480e+01,\n",
       "          9.59037495e+00,  1.59380920e-02,  1.24737082e+01,\n",
       "          1.25248647e+00, -1.13146410e+01, -2.50099991e-02,\n",
       "          8.33479500e+00, -9.94205996e-02, -5.52124166e+00,\n",
       "         -1.18837242e+01,  1.12508377e-03, -1.18252337e+00,\n",
       "         -1.01310368e+01, -5.84011745e+00,  1.67797196e+00,\n",
       "          1.18573227e+01, -9.91571426e+00,  5.77732455e-04,\n",
       "          1.04117355e+01,  1.08104925e+01, -7.49187803e+00,\n",
       "          9.84835207e-01, -1.03649740e+01, -9.22589600e-02,\n",
       "         -2.71055003e-04, -9.23859119e+00,  2.71952394e-02,\n",
       "         -1.31718569e+01, -1.17112675e+01, -2.58956657e-04,\n",
       "          8.51731561e-03,  8.67972565e+00,  2.91380167e+00,\n",
       "          1.29196472e+01,  1.15574036e+01,  5.48372008e-02,\n",
       "         -8.42366695e+00,  4.32991236e-03, -6.64383125e+00,\n",
       "         -1.16213500e-01,  5.62932051e-04,  5.31301543e-04,\n",
       "         -1.39997993e-03, -1.15475631e+00,  6.87967730e+00,\n",
       "          5.31188726e-01,  1.16090029e-02, -7.18991330e-04,\n",
       "          8.66174316e+00, -1.33447275e+01,  1.30492649e+01,\n",
       "         -2.16088653e-01, -1.15688763e+01, -1.13043383e-01,\n",
       "         -1.11466656e+01, -3.90786624e+00,  1.34409342e+01,\n",
       "         -1.24363880e+01,  4.48719948e-04,  6.10892251e-02,\n",
       "          1.04449244e+01,  7.36820628e-04, -3.73542738e+00,\n",
       "          2.48783365e-01]], dtype=float32)]"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_model.predict(input_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "target_seq[0, 0, target_token_index[\"\\t\"]] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 8, 26)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "       [[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names = [\"santhosh\",\"kumar\",\"anand\",\"joshi\"] # Samples\n",
    "\n",
    "import string \n",
    "\n",
    "# get the alphabest\n",
    "string.ascii_lowercase\n",
    "\n",
    "# List of Vocabulary\n",
    "vocabs_ = [x for x in string.ascii_lowercase] # Features\n",
    "\n",
    "# vocabulary length\n",
    "vocab_length = len(string.ascii_lowercase)\n",
    "\n",
    "# Max Sequence Length\n",
    "max_seq_length = max([len(x) for x in names])\n",
    "\n",
    "char_2_int = {} \n",
    "int_2_char = {}\n",
    "\n",
    "# Char to Interger \n",
    "char_2_int = dict([(x,i) for i,x in enumerate(vocabs_)])\n",
    "\n",
    "# Integer to Char\n",
    "int_2_char = dict([(i,x) for i,x in enumerate(vocabs_)])\n",
    "\n",
    "# Create Zero array for encoding\n",
    "\n",
    "encoding = np.zeros((len(names),max_seq_length,vocab_length))\n",
    "\n",
    "print(encoding.shape)  # (4 Samples,max length of samples,vocabulary Length\n",
    "\n",
    "# Update the encoder matrix for the samples\n",
    "\n",
    "for i,name in enumerate(names): # i = index value and i = sample and j =time step\n",
    "    for j,char in enumerate(name):\n",
    "        encoding[i,j,char_2_int[char]] = 1.0\n",
    "        \n",
    "encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "pedicted_Seq = [[0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
    "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
    "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
    "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
    "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
    "         0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
    "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
    "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
    "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
    "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
    "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
    "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
    "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
    "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
    "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
    "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "pedicted_Seq = np.asarray([np.asarray(pedicted_Seq)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(pedicted_Seq[0,2]).index(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s'"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_2_char[18]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
