{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy import argmax\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "data = [1, 3, 2, 0, 3, 2, 2, 1, 0, 1]\n",
    "data = np.array(data)\n",
    "\n",
    "encoded = to_categorical(data)\n",
    "\n",
    "encoded\n",
    "\n",
    "# 1 = [0., 1., 0., 0.]\n",
    "# 3 = [0., 0., 0., 1.]\n",
    "# 2 = [0., 0., 1., 0.]\n",
    "# 0 = [1., 0., 0., 0.]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "y = [1,2,3,4,5]\n",
    "\n",
    "to_categorical(y, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Thanks for an excellent report</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Your service is very quick and fast</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I am pleased with your service</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I did not know i was diabetic until you gave m...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Service - Little slow, probably because too ma...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0                     Thanks for an excellent report       pos\n",
       "1                Your service is very quick and fast       pos\n",
       "2                     I am pleased with your service       pos\n",
       "3  I did not know i was diabetic until you gave m...       neg\n",
       "4  Service - Little slow, probably because too ma...       neg"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train = [(\"Thanks for an excellent report\", \"pos\"),\n",
    "         (\"Your service is very quick and fast\", \"pos\"),\n",
    "        (\"I am pleased with your service\", \"pos\"),\n",
    "        (\"I did not know i was diabetic until you gave me this report\", \"neg\"),\n",
    "        (\"Service - Little slow, probably because too many people.\", \"neg\"),\n",
    "        (\"The place is not easy to locate\", \"neg\"),\n",
    "        (\"The place is very easy to locate\", \"pos\"),\n",
    "        (\"Not satisfied will take a second opinion\", \"neg\"),\n",
    "        (\"No human contact everything is so robotic here\", \"neg\")]\n",
    "\n",
    "df = pd.DataFrame(train,columns=['review','sentiment'])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "stopwords = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Thanks for an excellent report',\n",
       " 'Your service is very quick and fast',\n",
       " 'I am pleased with your service',\n",
       " 'I did not know i was diabetic until you gave me this report',\n",
       " 'Service - Little slow, probably because too many people.',\n",
       " 'The place is not easy to locate',\n",
       " 'The place is very easy to locate',\n",
       " 'Not satisfied will take a second opinion',\n",
       " 'No human contact everything is so robotic here']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = list(df['review'].values)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['thanks', 'excellent', 'report']\n",
      "['service', 'quick', 'fast']\n",
      "['pleased', 'service']\n",
      "['know', 'diabetic', 'gave', 'report']\n",
      "['service', 'little', 'slow', 'probably', 'many', 'people']\n",
      "['place', 'easy', 'locate']\n",
      "['place', 'easy', 'locate']\n",
      "['satisfied', 'take', 'second', 'opinion']\n",
      "['human', 'contact', 'everything', 'robotic']\n"
     ]
    }
   ],
   "source": [
    "data_token = [word_tokenize(x.lower()) for x in data]\n",
    "clean_data = []\n",
    "\n",
    "for sent in data_token:\n",
    "    print([x for x in sent if (x not in stopwords and x not in \"-.,\")])\n",
    "    clean_data.append([x for x in sent if (x not in stopwords and x not in \"-.,\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['thanks', 'excellent', 'report'],\n",
       " ['service', 'quick', 'fast'],\n",
       " ['pleased', 'service'],\n",
       " ['know', 'diabetic', 'gave', 'report'],\n",
       " ['service', 'little', 'slow', 'probably', 'many', 'people'],\n",
       " ['place', 'easy', 'locate'],\n",
       " ['place', 'easy', 'locate'],\n",
       " ['satisfied', 'take', 'second', 'opinion'],\n",
       " ['human', 'contact', 'everything', 'robotic']]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'quick': 1, 'excellent': 2, 'know': 3, 'probably': 4, 'report': 5, 'slow': 6, 'second': 7, 'diabetic': 8, 'fast': 9, 'locate': 10, 'satisfied': 11, 'thanks': 12, 'little': 13, 'service': 14, 'contact': 15, 'human': 16, 'easy': 17, 'place': 18, 'take': 19, 'robotic': 20, 'gave': 21, 'people': 22, 'everything': 23, 'many': 24, 'opinion': 25, 'pleased': 26}\n",
      "\n",
      "\n",
      "{1: 'quick', 2: 'excellent', 3: 'know', 4: 'probably', 5: 'report', 6: 'slow', 7: 'second', 8: 'diabetic', 9: 'fast', 10: 'locate', 11: 'satisfied', 12: 'thanks', 13: 'little', 14: 'service', 15: 'contact', 16: 'human', 17: 'easy', 18: 'place', 19: 'take', 20: 'robotic', 21: 'gave', 22: 'people', 23: 'everything', 24: 'many', 25: 'opinion', 26: 'pleased'}\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[12, 2, 5],\n",
       " [14, 1, 9],\n",
       " [26, 14],\n",
       " [3, 8, 21, 5],\n",
       " [14, 13, 6, 4, 24, 22],\n",
       " [18, 17, 10],\n",
       " [18, 17, 10],\n",
       " [11, 19, 7, 25],\n",
       " [16, 15, 23, 20]]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabs = list(set([val for sublist in clean_data for val in sublist]))\n",
    "\n",
    "# Get Word2Id\n",
    "word2id={}\n",
    "\n",
    "i = 1\n",
    "for vocab in vocabs:\n",
    "    case = {vocab:i}\n",
    "    word2id.update(case)\n",
    "    i= i+1\n",
    "    \n",
    "print(word2id)\n",
    "\n",
    "id2word = {v:k for k, v in word2id.items()}\n",
    "\n",
    "print(\"\\n\")\n",
    "print(id2word)\n",
    "\n",
    "print(\"\\n\")\n",
    "wids = [[word2id[y.lower()] for y in x] for x in clean_data]\n",
    "\n",
    "wids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 6)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0, 12,  2,  5],\n",
       "       [ 0,  0,  0, 14,  1,  9],\n",
       "       [ 0,  0,  0,  0, 26, 14],\n",
       "       [ 0,  0,  3,  8, 21,  5],\n",
       "       [14, 13,  6,  4, 24, 22],\n",
       "       [ 0,  0,  0, 18, 17, 10],\n",
       "       [ 0,  0,  0, 18, 17, 10],\n",
       "       [ 0,  0, 11, 19,  7, 25],\n",
       "       [ 0,  0, 16, 15, 23, 20]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing import sequence\n",
    "\n",
    "x = sequence.pad_sequences(wids, maxlen=6)\n",
    "\n",
    "print(x.shape)  # 9: Senetnces 6: max Lengt of Senetnce after cleanup\n",
    "\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "One Hot Encoding of input:\n",
      "[[[1. 0. 0. ... 0. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 1. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[1. 0. 0. ... 0. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 1. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[1. 0. 0. ... 0. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 1.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[1. 0. 0. ... 0. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[1. 0. 0. ... 0. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 1. 0.]]\n",
      "\n",
      " [[1. 0. 0. ... 0. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\")\n",
    "\n",
    "one_hot_arry = to_categorical(x)\n",
    "\n",
    "print(\"One Hot Encoding of input:\")\n",
    "print(one_hot_arry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
