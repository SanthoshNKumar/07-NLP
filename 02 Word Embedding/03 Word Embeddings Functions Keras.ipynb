{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "# define 5 documents\n",
    "docs = ['Well done!',\n",
    "        'Good work',\n",
    "        'Great effort',\n",
    "        'nice work',\n",
    "        'Excellent!']\n",
    "\n",
    "# create the tokenizer\n",
    "t = Tokenizer()\n",
    "\n",
    "# fit the tokenizer on the documents\n",
    "t.fit_on_texts(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('well', 1),\n",
       "             ('done', 1),\n",
       "             ('good', 1),\n",
       "             ('work', 2),\n",
       "             ('great', 1),\n",
       "             ('effort', 1),\n",
       "             ('nice', 1),\n",
       "             ('excellent', 1)])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.word_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'work': 1,\n",
       " 'well': 2,\n",
       " 'done': 3,\n",
       " 'good': 4,\n",
       " 'great': 5,\n",
       " 'effort': 6,\n",
       " 'nice': 7,\n",
       " 'excellent': 8}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.word_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Document Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.document_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text to Word Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'over', 'quick', 'lazy', 'jumped', 'brown', 'fox', 'dog', 'the'}\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import text_to_word_sequence\n",
    "\n",
    "# define the document\n",
    "text = 'The quick brown fox jumped over the lazy dog dog.'\n",
    "\n",
    "# estimate the size of the vocabulary\n",
    "words = set(text_to_word_sequence(text))\n",
    "\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Index Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 'work',\n",
       " 2: 'well',\n",
       " 3: 'done',\n",
       " 4: 'good',\n",
       " 5: 'great',\n",
       " 6: 'effort',\n",
       " 7: 'nice',\n",
       " 8: 'excellent'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example : using Keras Tokenizer\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "# define 5 documents\n",
    "docs = ['Well done!',\n",
    "        'Good work',\n",
    "        'Great effort',\n",
    "        'nice work',\n",
    "        'Excellent!']\n",
    "\n",
    "t = Tokenizer()\n",
    "\n",
    "t.fit_on_texts(docs)\n",
    "\n",
    "t.index_word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Hot Encoding: sequences_to_matrix (Binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 1., 1., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 1., 1., 0.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer(num_words=10)\n",
    "\n",
    "x_train = [[1,2,3,4],\n",
    "           [4,5,],\n",
    "           [6,7,8]]\n",
    "\n",
    "x_train = tokenizer.sequences_to_matrix(x_train, mode='binary')\n",
    "\n",
    "x_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Padding Sequence : pre and post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maxl:7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 3, 18,  9,  3, 11,  5, 20],\n",
       "       [ 0,  0,  0,  3,  8,  1, 12],\n",
       "       [ 0,  0,  0, 18,  1,  8,  1],\n",
       "       [ 0,  0,  0,  8,  1,  9, 14],\n",
       "       [ 0,  0,  0, 25,  1,  8,  1],\n",
       "       [ 0,  0,  0,  0,  0,  0,  9]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 1 : using Keras\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "\n",
    "data_vec = [['3', '18', '9', '3', '11', '5', '20'],\n",
    "            ['3', '8', '1', '12'],\n",
    "            ['18', '1', '8', '1'],\n",
    "            ['8', '1', '9', '14'],\n",
    "            ['25', '1', '8', '1'],\n",
    "            ['9']]\n",
    "\n",
    "maxl=np.max([len(x) for x in data_vec])\n",
    "\n",
    "print('maxl:{0}'.format(maxl))\n",
    "\n",
    "x_data_vec = sequence.pad_sequences(data_vec, maxlen=maxl)\n",
    "\n",
    "x_data_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3, 18,  9,  3, 11,  5, 20],\n",
       "       [ 0,  0,  0,  3,  8,  1, 12],\n",
       "       [ 0,  0,  0, 18,  1,  8,  1],\n",
       "       [ 0,  0,  0,  8,  1,  9, 14],\n",
       "       [ 0,  0,  0, 25,  1,  8,  1],\n",
       "       [ 0,  0,  0,  0,  0,  0,  9]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# padding = 'post'\n",
    "\n",
    "x_data_vec = sequence.pad_sequences(data_vec, maxlen=maxl,padding='pre')\n",
    "\n",
    "x_data_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3, 18,  9,  3, 11,  5, 20,  0,  0,  0],\n",
       "       [ 3,  8,  1, 12,  0,  0,  0,  0,  0,  0],\n",
       "       [18,  1,  8,  1,  0,  0,  0,  0,  0,  0],\n",
       "       [ 8,  1,  9, 14,  0,  0,  0,  0,  0,  0],\n",
       "       [25,  1,  8,  1,  0,  0,  0,  0,  0,  0],\n",
       "       [ 9,  0,  0,  0,  0,  0,  0,  0,  0,  0]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Max Length\n",
    "\n",
    "x_data_vec = sequence.pad_sequences(data_vec, maxlen=10,padding='post')\n",
    "\n",
    "x_data_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
