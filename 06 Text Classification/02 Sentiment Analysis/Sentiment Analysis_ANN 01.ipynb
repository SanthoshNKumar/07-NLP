{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "train = [(\"Thanks for an excellent report\", \"pos\"),\n",
    "         (\"Your service is very quick and fast\", \"pos\"),\n",
    "        (\"I am pleased with your service\", \"pos\"),\n",
    "        (\"I did not know i was diabetic until you gave me this report\", \"neg\"),\n",
    "        (\"Service - Little slow, probably because too many people.\", \"neg\"),\n",
    "        (\"The place is not easy to locate\", \"neg\"),\n",
    "        (\"The place is very easy to locate\", \"pos\"),\n",
    "        (\"Not satisfied will take a second opinion\", \"neg\"),\n",
    "        (\"No human contact everything is so robotic here\", \"neg\"),\n",
    "        (\"can i talk to a human not convinced with your report\", \"neg\"),\n",
    "        (\"good results\", \"pos\"),\n",
    "        (\"good service\", \"pos\"),\n",
    "        (\"great service\", \"pos\"),\n",
    "        (\"excellent service\", \"pos\"),\n",
    "        (\"amazing technology\", \"pos\"),\n",
    "        (\"fast service and satisfying report\", \"pos\"),\n",
    "        (\"your report sucks\", \"neg\"),\n",
    "        (\"this report will cost me a fortune\", \"neg\"),\n",
    "        (\"I have diabetes\", \"neg\"),\n",
    "        (\"this report will cost me a fortune\", \"neg\"),\n",
    "        (\"this report means i have a dreadful disease\", \"neg\"),\n",
    "        (\"will i need to take new medication\", \"neg\"),\n",
    "        (\"i need to take my insulin injections regularly\", \"neg\"),\n",
    "        (\"my lipids are getting worst need to talk to the doctor\", \"neg\"),\n",
    "        (\"oh my god very bad results\", \"neg\"),\n",
    "        (\"bad service\", \"neg\"),\n",
    "        (\"very bad service\", \"neg\"),\n",
    "        (\"poor service\", \"neg\"),\n",
    "        (\"very bad service\", \"neg\"),\n",
    "        (\"slow service\", \"neg\"),\n",
    "        (\"very slow service\", \"neg\"),\n",
    "        (\"diabetes got worst is this report accurate\", \"neg\"),\n",
    "        (\"i dont believe this report\", \"neg\"),\n",
    "        (\"i dont like this report\", \"neg\"),\n",
    "        (\"i am in a diabetic hell\", \"neg\"),]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(train,columns=['tweet','sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data\n",
    "\n",
    "# 1. lower case the data\n",
    "\n",
    "df['tweet'] = df['tweet'].apply(lambda x : x.lower())\n",
    "\n",
    "#2 Remove the stop words\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "df['tweet'] = df['tweet'].apply(lambda x: ' '.join([word for word in x.split() if word not in stop_words]))\n",
    "\n",
    "#3 Remove punctuation\n",
    "\n",
    "import string\n",
    "string.punctuation\n",
    "\n",
    "df['tweet'] = df['tweet'].apply(lambda x: ''.join([word for word in x if word not in string.punctuation]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['thanks',\n",
       " 'excellent',\n",
       " 'report',\n",
       " 'service',\n",
       " 'quick',\n",
       " 'fast',\n",
       " 'pleased',\n",
       " 'service',\n",
       " 'know',\n",
       " 'diabetic',\n",
       " 'gave',\n",
       " 'report',\n",
       " 'service',\n",
       " 'little',\n",
       " 'slow',\n",
       " 'probably',\n",
       " 'many',\n",
       " 'people',\n",
       " 'place',\n",
       " 'easy',\n",
       " 'locate',\n",
       " 'place',\n",
       " 'easy',\n",
       " 'locate',\n",
       " 'satisfied',\n",
       " 'take',\n",
       " 'second',\n",
       " 'opinion',\n",
       " 'human',\n",
       " 'contact',\n",
       " 'everything',\n",
       " 'robotic',\n",
       " 'talk',\n",
       " 'human',\n",
       " 'convinced',\n",
       " 'report',\n",
       " 'good',\n",
       " 'results',\n",
       " 'good',\n",
       " 'service',\n",
       " 'great',\n",
       " 'service',\n",
       " 'excellent',\n",
       " 'service',\n",
       " 'amazing',\n",
       " 'technology',\n",
       " 'fast',\n",
       " 'service',\n",
       " 'satisfying',\n",
       " 'report',\n",
       " 'report',\n",
       " 'sucks',\n",
       " 'report',\n",
       " 'cost',\n",
       " 'fortune',\n",
       " 'diabetes',\n",
       " 'report',\n",
       " 'cost',\n",
       " 'fortune',\n",
       " 'report',\n",
       " 'means',\n",
       " 'dreadful',\n",
       " 'disease',\n",
       " 'need',\n",
       " 'take',\n",
       " 'new',\n",
       " 'medication',\n",
       " 'need',\n",
       " 'take',\n",
       " 'insulin',\n",
       " 'injections',\n",
       " 'regularly',\n",
       " 'lipids',\n",
       " 'getting',\n",
       " 'worst',\n",
       " 'need',\n",
       " 'talk',\n",
       " 'doctor',\n",
       " 'oh',\n",
       " 'god',\n",
       " 'bad',\n",
       " 'results',\n",
       " 'bad',\n",
       " 'service',\n",
       " 'bad',\n",
       " 'service',\n",
       " 'poor',\n",
       " 'service',\n",
       " 'bad',\n",
       " 'service',\n",
       " 'slow',\n",
       " 'service',\n",
       " 'slow',\n",
       " 'service',\n",
       " 'diabetes',\n",
       " 'got',\n",
       " 'worst',\n",
       " 'report',\n",
       " 'accurate',\n",
       " 'dont',\n",
       " 'believe',\n",
       " 'report',\n",
       " 'dont',\n",
       " 'like',\n",
       " 'report',\n",
       " 'diabetic',\n",
       " 'hell']"
      ]
     },
     "execution_count": 502,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary = []\n",
    "\n",
    "[[vocabulary.append(w) for w in x.split()] for x in df['tweet']]\n",
    "\n",
    "vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of Vocabulary: 61\n"
     ]
    }
   ],
   "source": [
    "vocabulary = set(vocabulary)\n",
    "\n",
    "print(\"Size of Vocabulary:\",len(vocabulary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = {}\n",
    "\n",
    "for i,word in enumerate(sorted(vocabulary),0):\n",
    "    word_index[word] = i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61"
      ]
     },
     "execution_count": 505,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index\n",
    "\n",
    "len(word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_length = len(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = vocab_length\n",
    "rows = len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_matrix = np.zeros(shape=(rows,columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [[w for w in x.split()] for x in df['tweet']]\n",
    "\n",
    "data = [[word_index[w] for w in x.split()] for x in df['tweet']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(data)):\n",
    "    doc = data[i]\n",
    "    row = i\n",
    "    for j in range(len(doc)):\n",
    "        column = data[i][j]\n",
    "        vocab_matrix[i][column] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['sentiment'].map({'pos':1,'neg':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(500,activation='relu',input_dim=61))\n",
    "model.add(Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_10 (Dense)             (None, 500)               31000     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 501       \n",
      "=================================================================\n",
      "Total params: 31,501\n",
      "Trainable params: 31,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "35/35 [==============================] - 0s 3ms/step - loss: 0.6928 - accuracy: 0.4857\n",
      "Epoch 2/10\n",
      "35/35 [==============================] - 0s 114us/step - loss: 0.6402 - accuracy: 0.8286\n",
      "Epoch 3/10\n",
      "35/35 [==============================] - 0s 115us/step - loss: 0.5968 - accuracy: 0.8000\n",
      "Epoch 4/10\n",
      "35/35 [==============================] - 0s 229us/step - loss: 0.5603 - accuracy: 0.7714\n",
      "Epoch 5/10\n",
      "35/35 [==============================] - 0s 114us/step - loss: 0.5253 - accuracy: 0.7714\n",
      "Epoch 6/10\n",
      "35/35 [==============================] - 0s 114us/step - loss: 0.4959 - accuracy: 0.7714\n",
      "Epoch 7/10\n",
      "35/35 [==============================] - 0s 228us/step - loss: 0.4691 - accuracy: 0.7714\n",
      "Epoch 8/10\n",
      "35/35 [==============================] - 0s 114us/step - loss: 0.4447 - accuracy: 0.8000\n",
      "Epoch 9/10\n",
      "35/35 [==============================] - 0s 229us/step - loss: 0.4213 - accuracy: 0.8286\n",
      "Epoch 10/10\n",
      "35/35 [==============================] - 0s 227us/step - loss: 0.3983 - accuracy: 0.8286\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x19cba091948>"
      ]
     },
     "execution_count": 515,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(vocab_matrix,y,epochs=10,batch_size=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertOneHotEncoding(txt):\n",
    "    data = txt.split()\n",
    "    matrix = np.zeros((1,61))\n",
    "    for i in range(len(data)):\n",
    "        val = word_index[data[i]]\n",
    "        matrix[0][val] = 1\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictSentiment(text):\n",
    "    text = text.lower()\n",
    "    val = model.predict(convertOneHotEncoding(text))\n",
    "    if val>0.5:\n",
    "        print('Positive')\n",
    "    else:\n",
    "        print('Negative')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative\n"
     ]
    }
   ],
   "source": [
    "predictSentiment('good')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
