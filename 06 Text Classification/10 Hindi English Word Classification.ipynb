{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hindi_English_Word Classifcation\n",
    "\n",
    "# Step1 : read the dataset(label)\n",
    "# Step2 : Create word2Id dictionary for the ascii\n",
    "#           {'a': 1, 'b': 2, 'c': 3, 'd': 4, 'e': 5....}\n",
    "# Step 3: Create the Charters Matrix for the word Corpus\n",
    "#        [['c', 'r', 'i', 'c', 'k', 'e', 't'],['c', 'h', 'a', 'l'],['r', 'a', 'h', 'a']]......\n",
    "#Step 4: Convert word to respected Interger value(Sequence matrix)\n",
    "#        [[3, 18, 9, 3, 11, 5, 20], [3, 8, 1, 12], [18, 1, 8, 1]]\n",
    "#Step 5: Padding the Sequcne of max length = 30\n",
    "#        array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
    "#                0,  0,  0,  0,  0,  0,  3, 18,  9,  3, 11,  5, 20])\n",
    "#Step 6: Encode the target values {0:\"English\",1:\"Hindi\"}\n",
    "#Step 7: Create Keras model alsog with LSTM layers\n",
    "#Step 8: Reshape the X_doc_vec to 3D\n",
    "#        X_train=X_train.reshape(10199,30,1)\n",
    "#Step 9: Crate Prediction function which reads and convert to respected vector form for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "data = pd.read_csv(r\"New_Hinglish_Classification_final_1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12749, 3)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>english</th>\n",
       "      <th>Word</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>cricket</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>chal</td>\n",
       "      <td>hi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>raha</td>\n",
       "      <td>hi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   english     Word label\n",
       "0        0  cricket    en\n",
       "1        1     chal    hi\n",
       "2        2     raha    hi"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['label'] = data['label'].map({'en':\"English\",'hi':\"Hindi\"})\n",
    "\n",
    "data = data[['Word','label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['label_encoded'] = data['label'].map({\"English\":0,\"Hindi\":1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>label</th>\n",
       "      <th>label_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>cricket</td>\n",
       "      <td>English</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>chal</td>\n",
       "      <td>Hindi</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>raha</td>\n",
       "      <td>Hindi</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>hain</td>\n",
       "      <td>Hindi</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>yaha</td>\n",
       "      <td>Hindi</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Word    label  label_encoded\n",
       "0  cricket  English              0\n",
       "1     chal    Hindi              1\n",
       "2     raha    Hindi              1\n",
       "3     hain    Hindi              1\n",
       "4     yaha    Hindi              1"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "English    6935\n",
       "Hindi      5814\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Word             0\n",
       "label            0\n",
       "label_encoded    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': 1, 'b': 2, 'c': 3, 'd': 4, 'e': 5, 'f': 6, 'g': 7, 'h': 8, 'i': 9, 'j': 10, 'k': 11, 'l': 12, 'm': 13, 'n': 14, 'o': 15, 'p': 16, 'q': 17, 'r': 18, 's': 19, 't': 20, 'u': 21, 'v': 22, 'w': 23, 'x': 24, 'y': 25, 'z': 26}\n"
     ]
    }
   ],
   "source": [
    "# Create a dictionary for alphabets and integer value\n",
    "\n",
    "from string import ascii_lowercase\n",
    "\n",
    "od = dict(((x,y) for y,x in enumerate(ascii_lowercase,1)))\n",
    "\n",
    "print(od)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          cricket\n",
       "1             chal\n",
       "2             raha\n",
       "3             hain\n",
       "4             yaha\n",
       "           ...    \n",
       "12744    challenge\n",
       "12745      winners\n",
       "12746           at\n",
       "12747     paradise\n",
       "12748       photos\n",
       "Name: Word, Length: 12749, dtype: object"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocessing :Lower case the word\n",
    "\n",
    "data['Word'].apply(lambda x : x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['c', 'r', 'i', 'c', 'k', 'e', 't'],\n",
       " ['c', 'h', 'a', 'l'],\n",
       " ['r', 'a', 'h', 'a'],\n",
       " ['h', 'a', 'i', 'n'],\n",
       " ['y', 'a', 'h', 'a'],\n",
       " ['i'],\n",
       " ['l', 'i', 'k', 'e', 'd'],\n",
       " ['a'],\n",
       " ['y', 'o', 'u', 't', 'u', 'b', 'e'],\n",
       " ['v', 'i', 'd', 'e', 'o']]"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#list(data['label'])\n",
    "\n",
    "word = [x for x in list(data['Word'])]\n",
    "word_vec = [[char for char in s] for s in labels]\n",
    "\n",
    "word_vec[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['E', 'n', 'g', 'l', 'i', 's', 'h']"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2id(word):\n",
    "    new_vec = []\n",
    "    \n",
    "    word = word.lower()\n",
    "    \n",
    "    vec = []\n",
    "    for j in word:\n",
    "        value = od[j]\n",
    "        vec.append(value)\n",
    "    new_vec.append(vec)\n",
    "    \n",
    "    return new_vec[0]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 14, 7, 12, 9, 19, 8]"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2id(\"English\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[3, 18, 9, 3, 11, 5, 20], [3, 8, 1, 12], [18, 1, 8, 1], [8, 1, 9, 14]]"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace the char to repected integet value\n",
    "\n",
    "word_vec[:2]\n",
    "\n",
    "# Contins sequence Matrix\n",
    "new_vec = []\n",
    "\n",
    "for x in word_vec:\n",
    "    vec = []\n",
    "    for j in x:\n",
    "        value = od[j]\n",
    "        vec.append(value)\n",
    "    new_vec.append(vec)\n",
    "    \n",
    "# Interger encoding of the word_vec\n",
    "new_vec[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# padding\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "maxl = 30\n",
    "x_data_vec = pad_sequences(new_vec, maxlen=maxl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12749, 30)"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data_vec.shape # 12749 rows of data and sequence length of 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  3, 18,  9,  3, 11,  5, 20])"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data_vec[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12749,)"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data_vec = np.array(data['label_encoded'])\n",
    "\n",
    "y_data_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12749, 30)"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(x_data_vec, y_data_vec, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10199, 30)"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2550, 30)"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10199,)"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshare the vectors for LSTM \n",
    "\n",
    "X_train=X_train.reshape(10199,30,1)\n",
    "X_test=X_test.reshape(2550,30,1)\n",
    "Y_train=Y_train.reshape(10199,1)\n",
    "Y_test=Y_test.reshape(2550,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\insakum46\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 30, 128)           66560     \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 64)                49408     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 116,033\n",
      "Trainable params: 116,033\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "\n",
    "\n",
    "model_classifier =Sequential()\n",
    "model_classifier.add(LSTM(128, return_sequences = True, input_shape = (X_train.shape[1], 1)))\n",
    "model_classifier.add(LSTM(64, activation='tanh'))\n",
    "model_classifier.add(Dense(1, activation='sigmoid'))\n",
    "#model_classifier.add(Dense(2, activation='softmax'))\n",
    "model_classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\insakum46\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_core\\python\\ops\\nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "# try using different optimizers and different optimizer configs\n",
    "model_classifier.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\insakum46\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 10199 samples, validate on 2550 samples\n",
      "Epoch 1/50\n",
      "10199/10199 [==============================] - 14s 1ms/step - loss: 0.6038 - accuracy: 0.6659 - val_loss: 0.5686 - val_accuracy: 0.7129\n",
      "Epoch 2/50\n",
      "10199/10199 [==============================] - 13s 1ms/step - loss: 0.5580 - accuracy: 0.7162 - val_loss: 0.5524 - val_accuracy: 0.7204\n",
      "Epoch 3/50\n",
      "10199/10199 [==============================] - 13s 1ms/step - loss: 0.5401 - accuracy: 0.7255 - val_loss: 0.5509 - val_accuracy: 0.7231\n",
      "Epoch 4/50\n",
      "10199/10199 [==============================] - 13s 1ms/step - loss: 0.5264 - accuracy: 0.7314 - val_loss: 0.5355 - val_accuracy: 0.7169\n",
      "Epoch 5/50\n",
      "10199/10199 [==============================] - 13s 1ms/step - loss: 0.5179 - accuracy: 0.7384 - val_loss: 0.5210 - val_accuracy: 0.7208\n",
      "Epoch 6/50\n",
      "10199/10199 [==============================] - 13s 1ms/step - loss: 0.4994 - accuracy: 0.7500 - val_loss: 0.5199 - val_accuracy: 0.7341\n",
      "Epoch 7/50\n",
      "10199/10199 [==============================] - 13s 1ms/step - loss: 0.4884 - accuracy: 0.7514 - val_loss: 0.5064 - val_accuracy: 0.7388\n",
      "Epoch 8/50\n",
      "10199/10199 [==============================] - 13s 1ms/step - loss: 0.4740 - accuracy: 0.7599 - val_loss: 0.4817 - val_accuracy: 0.7431\n",
      "Epoch 9/50\n",
      "10199/10199 [==============================] - 13s 1ms/step - loss: 0.4680 - accuracy: 0.7630 - val_loss: 0.4768 - val_accuracy: 0.7573\n",
      "Epoch 10/50\n",
      "10199/10199 [==============================] - 13s 1ms/step - loss: 0.4527 - accuracy: 0.7707 - val_loss: 0.4706 - val_accuracy: 0.7671\n",
      "Epoch 11/50\n",
      "10199/10199 [==============================] - 13s 1ms/step - loss: 0.4468 - accuracy: 0.7776 - val_loss: 0.4541 - val_accuracy: 0.7827\n",
      "Epoch 12/50\n",
      "10199/10199 [==============================] - 13s 1ms/step - loss: 0.4354 - accuracy: 0.7869 - val_loss: 0.4466 - val_accuracy: 0.7737\n",
      "Epoch 13/50\n",
      "10199/10199 [==============================] - 13s 1ms/step - loss: 0.4263 - accuracy: 0.7936 - val_loss: 0.4429 - val_accuracy: 0.7773\n",
      "Epoch 14/50\n",
      "10199/10199 [==============================] - 13s 1ms/step - loss: 0.4173 - accuracy: 0.7969 - val_loss: 0.4388 - val_accuracy: 0.7843\n",
      "Epoch 15/50\n",
      "10199/10199 [==============================] - 14s 1ms/step - loss: 0.4021 - accuracy: 0.8139 - val_loss: 0.4265 - val_accuracy: 0.8051\n",
      "Epoch 16/50\n",
      "10199/10199 [==============================] - 13s 1ms/step - loss: 0.3960 - accuracy: 0.8213 - val_loss: 0.4276 - val_accuracy: 0.8129\n",
      "Epoch 17/50\n",
      "10199/10199 [==============================] - 13s 1ms/step - loss: 0.3874 - accuracy: 0.8256 - val_loss: 0.4158 - val_accuracy: 0.8051\n",
      "Epoch 18/50\n",
      "10199/10199 [==============================] - 13s 1ms/step - loss: 0.3730 - accuracy: 0.8371 - val_loss: 0.4195 - val_accuracy: 0.8051\n",
      "Epoch 19/50\n",
      "10199/10199 [==============================] - 13s 1ms/step - loss: 0.3644 - accuracy: 0.8372 - val_loss: 0.4033 - val_accuracy: 0.8204\n",
      "Epoch 20/50\n",
      "10199/10199 [==============================] - 13s 1ms/step - loss: 0.3584 - accuracy: 0.8382 - val_loss: 0.3979 - val_accuracy: 0.8376\n",
      "Epoch 21/50\n",
      "10199/10199 [==============================] - 13s 1ms/step - loss: 0.3436 - accuracy: 0.8514 - val_loss: 0.4065 - val_accuracy: 0.8259\n",
      "Epoch 22/50\n",
      "10199/10199 [==============================] - 13s 1ms/step - loss: 0.3363 - accuracy: 0.8575 - val_loss: 0.3914 - val_accuracy: 0.8416\n",
      "Epoch 23/50\n",
      "10199/10199 [==============================] - 13s 1ms/step - loss: 0.3269 - accuracy: 0.8609 - val_loss: 0.3846 - val_accuracy: 0.8471\n",
      "Epoch 24/50\n",
      "10199/10199 [==============================] - 14s 1ms/step - loss: 0.3196 - accuracy: 0.8590 - val_loss: 0.3859 - val_accuracy: 0.8490\n",
      "Epoch 25/50\n",
      "10199/10199 [==============================] - 13s 1ms/step - loss: 0.3124 - accuracy: 0.8619 - val_loss: 0.3745 - val_accuracy: 0.8302\n",
      "Epoch 26/50\n",
      "10199/10199 [==============================] - 13s 1ms/step - loss: 0.3002 - accuracy: 0.8699 - val_loss: 0.3743 - val_accuracy: 0.8498\n",
      "Epoch 27/50\n",
      "10199/10199 [==============================] - 13s 1ms/step - loss: 0.2938 - accuracy: 0.8767 - val_loss: 0.3651 - val_accuracy: 0.8588\n",
      "Epoch 28/50\n",
      "10199/10199 [==============================] - 13s 1ms/step - loss: 0.2871 - accuracy: 0.8780 - val_loss: 0.3666 - val_accuracy: 0.8506\n",
      "Epoch 29/50\n",
      "10199/10199 [==============================] - 13s 1ms/step - loss: 0.2811 - accuracy: 0.8822 - val_loss: 0.3639 - val_accuracy: 0.8463\n",
      "Epoch 30/50\n",
      "10199/10199 [==============================] - 13s 1ms/step - loss: 0.2741 - accuracy: 0.8822 - val_loss: 0.3806 - val_accuracy: 0.8541\n",
      "Epoch 31/50\n",
      "10199/10199 [==============================] - 13s 1ms/step - loss: 0.2700 - accuracy: 0.8818 - val_loss: 0.3579 - val_accuracy: 0.8553\n",
      "Epoch 32/50\n",
      "10199/10199 [==============================] - 13s 1ms/step - loss: 0.2617 - accuracy: 0.8877 - val_loss: 0.3594 - val_accuracy: 0.8549\n",
      "Epoch 33/50\n",
      "10199/10199 [==============================] - 13s 1ms/step - loss: 0.2544 - accuracy: 0.8912 - val_loss: 0.3490 - val_accuracy: 0.8604\n",
      "Epoch 34/50\n",
      "10199/10199 [==============================] - 13s 1ms/step - loss: 0.2486 - accuracy: 0.8933 - val_loss: 0.3474 - val_accuracy: 0.8584\n",
      "Epoch 35/50\n",
      "10199/10199 [==============================] - 13s 1ms/step - loss: 0.2448 - accuracy: 0.8974 - val_loss: 0.3461 - val_accuracy: 0.8714\n",
      "Epoch 36/50\n",
      "10199/10199 [==============================] - 13s 1ms/step - loss: 0.2385 - accuracy: 0.8972 - val_loss: 0.3539 - val_accuracy: 0.8655\n",
      "Epoch 37/50\n",
      "10199/10199 [==============================] - 13s 1ms/step - loss: 0.2347 - accuracy: 0.8971 - val_loss: 0.3401 - val_accuracy: 0.8675\n",
      "Epoch 38/50\n",
      "10199/10199 [==============================] - 13s 1ms/step - loss: 0.2328 - accuracy: 0.8998 - val_loss: 0.3402 - val_accuracy: 0.8682\n",
      "Epoch 39/50\n",
      "10199/10199 [==============================] - 12s 1ms/step - loss: 0.2280 - accuracy: 0.9040 - val_loss: 0.3455 - val_accuracy: 0.8702\n",
      "Epoch 40/50\n",
      "10199/10199 [==============================] - 13s 1ms/step - loss: 0.2228 - accuracy: 0.9043 - val_loss: 0.3479 - val_accuracy: 0.8706\n",
      "Epoch 41/50\n",
      "10199/10199 [==============================] - 13s 1ms/step - loss: 0.2154 - accuracy: 0.9089 - val_loss: 0.3354 - val_accuracy: 0.8792\n",
      "Epoch 42/50\n",
      "10199/10199 [==============================] - 13s 1ms/step - loss: 0.2127 - accuracy: 0.9109 - val_loss: 0.3360 - val_accuracy: 0.8675\n",
      "Epoch 43/50\n",
      "10199/10199 [==============================] - 13s 1ms/step - loss: 0.2072 - accuracy: 0.9143 - val_loss: 0.3520 - val_accuracy: 0.8733\n",
      "Epoch 44/50\n",
      "10199/10199 [==============================] - 14s 1ms/step - loss: 0.2034 - accuracy: 0.9154 - val_loss: 0.3301 - val_accuracy: 0.8800\n",
      "Epoch 45/50\n",
      "10199/10199 [==============================] - 13s 1ms/step - loss: 0.1996 - accuracy: 0.9151 - val_loss: 0.3430 - val_accuracy: 0.8784\n",
      "Epoch 46/50\n",
      "10199/10199 [==============================] - 13s 1ms/step - loss: 0.2011 - accuracy: 0.9172 - val_loss: 0.3517 - val_accuracy: 0.8631\n",
      "Epoch 47/50\n",
      "10199/10199 [==============================] - 13s 1ms/step - loss: 0.1941 - accuracy: 0.9201 - val_loss: 0.3439 - val_accuracy: 0.8800\n",
      "Epoch 48/50\n",
      "10199/10199 [==============================] - 13s 1ms/step - loss: 0.1959 - accuracy: 0.9155 - val_loss: 0.3275 - val_accuracy: 0.8780\n",
      "Epoch 49/50\n",
      "10199/10199 [==============================] - 13s 1ms/step - loss: 0.1906 - accuracy: 0.9212 - val_loss: 0.3369 - val_accuracy: 0.8804\n",
      "Epoch 50/50\n",
      "10199/10199 [==============================] - 13s 1ms/step - loss: 0.1846 - accuracy: 0.9261 - val_loss: 0.3595 - val_accuracy: 0.8729\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1c7b870cf08>"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_classifier.fit(X_train, Y_train,batch_size=128,epochs=50,validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 30)"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad_sequences([word2id(\"english\")], maxlen=maxl).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "X_train.reshape(10199,30,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict = {0:\"English\",1:\"Hindi\"}\n",
    "\n",
    "'''Method to preidct the Language'''\n",
    "def predictLanguage(model,word):\n",
    "    \n",
    "    # Word 2 vector conversion\n",
    "    word_vec = pad_sequences([word2id(word)], maxlen=maxl)\n",
    "    \n",
    "    # Reshape the vector 3D\n",
    "    word_vec = word_vec.reshape(1,30,1)\n",
    "    \n",
    "    # Predict the word from model\n",
    "    pred = model.predict(word_vec)\n",
    "    \n",
    "    pred_output = pred[0,0]\n",
    "    \n",
    "    # Set the boundry\n",
    "    if pred_output >= 0.5:\n",
    "        output = 1\n",
    "    else:\n",
    "        output = 0\n",
    "    \n",
    "    # return thr output\n",
    "    return dict[output]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hindi'"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictLanguage(model_classifier,\"kya\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose a random element from a list\n",
    "from random import seed\n",
    "from random import choice\n",
    "# seed random number generator\n",
    "seed(1)\n",
    "# prepare a sequence\n",
    "sequence = [i for i in range(20)]\n",
    "# make choices from the sequence\n",
    "\n",
    "index = []\n",
    "\n",
    "for _ in range(10):\n",
    "    selection = choice(sequence)\n",
    "    index.append(selection)\n",
    "    \n",
    "actual_output = []\n",
    "predicted_output = []\n",
    "\n",
    "df = data.iloc[index,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>label</th>\n",
       "      <th>label_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>yaha</td>\n",
       "      <td>Hindi</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>cover</td>\n",
       "      <td>English</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>raha</td>\n",
       "      <td>Hindi</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>youtube</td>\n",
       "      <td>English</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>hain</td>\n",
       "      <td>Hindi</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>kishore</td>\n",
       "      <td>Hindi</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>hai</td>\n",
       "      <td>Hindi</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>kishore</td>\n",
       "      <td>Hindi</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>pe</td>\n",
       "      <td>Hindi</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>liked</td>\n",
       "      <td>English</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Word    label  label_encoded\n",
       "4      yaha    Hindi              1\n",
       "18    cover  English              0\n",
       "2      raha    Hindi              1\n",
       "8   youtube  English              0\n",
       "3      hain    Hindi              1\n",
       "15  kishore    Hindi              1\n",
       "14      hai    Hindi              1\n",
       "15  kishore    Hindi              1\n",
       "12       pe    Hindi              1\n",
       "6     liked  English              0"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df.iterrows():\n",
    "    \n",
    "    actual_output.append(row['label'])\n",
    "    \n",
    "    word = row['Word']\n",
    "    \n",
    "    predicted_output.append(predictLanguage(model_classifier,word))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Hindi</td>\n",
       "      <td>Hindi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>English</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Hindi</td>\n",
       "      <td>Hindi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>English</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Hindi</td>\n",
       "      <td>Hindi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Hindi</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Hindi</td>\n",
       "      <td>Hindi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>Hindi</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>Hindi</td>\n",
       "      <td>Hindi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>English</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Actual Predicted\n",
       "0    Hindi     Hindi\n",
       "1  English   English\n",
       "2    Hindi     Hindi\n",
       "3  English   English\n",
       "4    Hindi     Hindi\n",
       "5    Hindi   English\n",
       "6    Hindi     Hindi\n",
       "7    Hindi   English\n",
       "8    Hindi     Hindi\n",
       "9  English   English"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\"Actual\":actual_output,\"Predicted\":predicted_output})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
