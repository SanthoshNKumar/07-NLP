{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing Copus Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "['adventure', 'belles_lettres', 'editorial', 'fiction', 'government', 'hobbies', 'humor', 'learned', 'lore', 'mystery', 'news', 'religion', 'reviews', 'romance', 'science_fiction']\n"
     ]
    }
   ],
   "source": [
    "# Load the Brown Corpus\n",
    "from nltk.corpus import brown\n",
    "\n",
    "# Find Categories\n",
    "print(len(brown.categories()))\n",
    "print(brown.categories())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['There', 'were', 'thirty-eight', 'patients', 'on', 'the', 'bus', 'the', 'morning', 'I', 'left', 'for', 'Hanover', ',', 'most', 'of', 'them', 'disturbed', 'and', 'hallucinating', '.'], ['An', 'interne', ',', 'a', 'nurse', 'and', 'two', 'attendants', 'were', 'in', 'charge', 'of', 'us', '.'], ...]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get Code snippet from where mystery categoreis\n",
    "brown.sents(categories ='mystery')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('There', 'EX'), ('were', 'BED'), ('thirty-eight', 'CD'), ('patients', 'NNS'), ('on', 'IN'), ('the', 'AT'), ('bus', 'NN'), ('the', 'AT'), ('morning', 'NN'), ('I', 'PPSS'), ('left', 'VBD'), ('for', 'IN'), ('Hanover', 'NP'), (',', ','), ('most', 'AP'), ('of', 'IN'), ('them', 'PPO'), ('disturbed', 'VBN'), ('and', 'CC'), ('hallucinating', 'VBG'), ('.', '.')], [('An', 'AT'), ('interne', 'NN'), (',', ','), ('a', 'AT'), ('nurse', 'NN'), ('and', 'CC'), ('two', 'CD'), ('attendants', 'NNS'), ('were', 'BED'), ('in', 'IN'), ('charge', 'NN'), ('of', 'IN'), ('us', 'PPO'), ('.', '.')], ...]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get POS tagged sentences\n",
    "brown.tagged_sents(categories ='mystery')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the Sentences in natural from\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "sentences = brown.sents(categories='mystery')\n",
    "sentences = [' '.join(sent_tokenize) for sent_tokenize in sentences]\n",
    "\n",
    "#print(sentences) # view Full text\n",
    "\n",
    "#print(sentences[:5]) # Viewing fist 5 sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('patients', 'NNS'), ('bus', 'NN'), ('morning', 'NN'), ('Hanover', 'NP'), ('interne', 'NN'), ('nurse', 'NN'), ('attendants', 'NNS'), ('charge', 'NN'), ('bus', 'NN'), ('window', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "# Get the Nouns from tagged words\n",
    "tagged_words = brown.tagged_words(categories='mystery')\n",
    "nouns = [(word,tag) for word, tag in tagged_words if any(noun_tag in tag for noun_tag in ['NP','NN'])]\n",
    "\n",
    "#Viewing the first 10 snouns\n",
    "print(nouns[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('man', 106),\n",
       " ('time', 82),\n",
       " ('door', 80),\n",
       " ('car', 69),\n",
       " ('room', 65),\n",
       " ('Mr.', 63),\n",
       " ('way', 61),\n",
       " ('office', 50),\n",
       " ('eyes', 48),\n",
       " ('hand', 46)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import FreqDist\n",
    "\n",
    "# Building Frequency distribution for nouns\n",
    "\n",
    "nouns_freq = FreqDist([word for word,tag in nouns])\n",
    "\n",
    "#Viewing top 10 occuring nouns\n",
    "nouns_freq.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"YUGOSLAV ECONOMY WORSENED IN 1986 , BANK DATA SHOWS National Bank economic data for 1986 shows that Yugoslavia ' s trade deficit grew , the inflation rate rose , wages were sharply higher , the money supply expanded and the value of the dinar fell .\",\n",
       " 'The trade deficit for 1986 was 2 . 012 billion dlrs , 25 . 7 pct higher than in 1985 .',\n",
       " 'The trend continued in the first three months of this year as exports dropped by 17 . 8 pct , in hard currency terms , to 2 . 124 billion dlrs .',\n",
       " 'Yugoslavia this year started quoting trade figures in dinars based on current exchange rates , instead of dollars based on a fixed exchange rate of 264 . 53 dinars per dollar .']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Accessing the Reuters Corpus\n",
    "from nltk.corpus import reuters\n",
    "\n",
    "# Get the length of the categories\n",
    "# print(len(reuters.categories()))\n",
    "# print the Categories \n",
    "# print(reuters.categories())\n",
    "# Get sentences in housing and income\n",
    "sentences = reuters.sents(categories = ['housing','income'])\n",
    "\n",
    "# Display in Natural Language\n",
    "sentences = [' '.join(sent_tokenize) for sent_tokenize in sentences]\n",
    "\n",
    "# Viewing first 5 sentences\n",
    "# sentences[0:5]\n",
    "\n",
    "# Filed ID based access \n",
    "# print(reuters.fileids(categories = ['housing','income']))\n",
    "\n",
    "# print(reuters.sents(fileids = [u'test/16118',u'test/18534']))\n",
    "\n",
    "sentences[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('hike.n.01'), Synset('rise.n.09'), Synset('raise.n.01'), Synset('hike.v.01'), Synset('hike.v.02')]\n"
     ]
    }
   ],
   "source": [
    "# Accessing Wordnet Corpus\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "word = 'hike'\n",
    "\n",
    "# get word synsets\n",
    "word_synsets = wn.synsets(word)\n",
    "print(word_synsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['[The', 'King', 'James', 'Bible]']]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import gutenberg\n",
    "bible = gutenberg.open('bible-kjv.txt')\n",
    "\n",
    "bible = bible.readlines()\n",
    "\n",
    "token = [item.split() for item in bible]\n",
    "\n",
    "token[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('It', 'PRP'), ('a', 'DT'), ('beautiful', 'JJ'), ('home', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "from nltk import pos_tag\n",
    "\n",
    "text = \"It  a beautiful home\"\n",
    "print(pos_tag(text.split()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"hadn't\", 'few', \"shouldn't\", 'won', \"don't\", 'ours', 'isn', 'who', 'the', 'being', 'if', 'mightn', \"you've\", 'no', \"she's\", 'o', 'about', 'same', 'its', 'we', 'wasn', 'this', 'against', 'up', 'she', 'where', 'my', 'himself', 'be', 'there', 'm', \"aren't\", 'hasn', 'when', 'some', 'been', 'am', 'that', 'by', 'other', 'me', 'him', \"wasn't\", 'for', 'which', 'wouldn', 'such', 've', 'don', 're', 'each', 'further', 'than', 'hers', 'or', 'down', 'haven', \"you're\", 'herself', 'doing', \"isn't\", 'y', 'before', 'with', 'her', 'on', \"mightn't\", 'only', \"that'll\", 'll', 'aren', 'off', 'an', 'out', 'your', 'themselves', 'here', 'all', \"hasn't\", 'ourselves', 'did', 'more', 'nor', 'in', 'just', 'not', \"won't\", 'very', 'what', 'into', \"mustn't\", 'will', 'of', 'yourself', 'shan', 'a', \"needn't\", \"wouldn't\", 'you', 'itself', 'has', 'was', 'then', \"you'll\", 'now', 'because', 'were', 'should', 'ma', 'having', 'whom', 'can', 'didn', \"shan't\", 'most', 'from', 'while', 'his', 'those', 'at', 'how', 'they', \"didn't\", \"should've\", 'doesn', 'to', 'couldn', 'shouldn', 's', 'ain', \"couldn't\", 'and', 'too', 'until', 'theirs', 'during', 'is', 'again', 'mustn', 'd', \"you'd\", 'but', 'myself', 'through', 'he', 'below', 'own', 'why', 'these', 'our', 'are', 'it', 'them', 'as', \"doesn't\", 'yours', 'after', 'hadn', 'does', 'over', 'had', 'do', 'both', \"weren't\", 'needn', 'weren', \"haven't\", 'their', 'once', 'yourselves', 't', 'above', 'have', 'between', 'under', 'i', 'any', 'so', \"it's\"}\n"
     ]
    }
   ],
   "source": [
    "# Print Stop words\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = set(stopwords.words('english'))\n",
    "print(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['game', 'game', 'game', 'game']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "words = ['game','gaming','gamed','games']\n",
    "stemwords = [PorterStemmer().stem(v) for v in words]\n",
    "print(stemwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corpus_Entailments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('see.v.01')]\n",
      "[Synset('hear.v.01')]\n",
      "[Synset('choose.v.01'), Synset('pay.v.01')]\n"
     ]
    }
   ],
   "source": [
    "# Entaiments : An entailment is an Implication.\n",
    "# Example : Looking implices seeing, Buying Implies choosing and paying \n",
    "\n",
    "from nltk.corpus import wordnet as wn\n",
    "print(wn.synset('look.v.01').entailments()) # out : [Synset('see.v.01')]\n",
    "\n",
    "print(wn.synset('listen.v.01').entailments()) # output : [Synset('hear.v.01')]\n",
    "\n",
    "print(wn.synset('buy.v.01').entailments()) #  output : [Synset('choose.v.01'), Synset('pay.v.01')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corpus_FrequencyDistribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ", 539\n",
      "bag: 4867\n",
      "[(',', 539), ('.', 353), ('/', 110), ('for', 99), ('and', 74), ('to', 74), ('lady', 68), ('-', 66), ('seeks', 60), ('a', 52)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x22c6f6eeb88>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import webtext\n",
    "#print(webtext.fileids())\n",
    "\n",
    "fileid = 'singles.txt'\n",
    "wbt_words = webtext.words('singles.txt') # Get the words based on file id\n",
    "# print(wbt_words)\n",
    "\n",
    "fdist = nltk.FreqDist(wbt_words) \n",
    "\n",
    "# Count of the maximum appearing token\n",
    "print(fdist.max(),fdist[fdist.max()])\n",
    "\n",
    "#Total number of distinct tokens in the bag\n",
    "print(\"bag:\",fdist.N())\n",
    "\n",
    "# Most common 10 words in the bag\n",
    "print(fdist.most_common(10))\n",
    "\n",
    "# Plot Graph\n",
    "fdist.plot(cumulative = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corpus_MeronymsAndHolonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('bedstead.n.01'), Synset('mattress.n.01')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Meronym : Meronym is a word that denotes a constituent part or a member of something.\n",
    "# Example : apple is a meronym of apple tree\n",
    "\n",
    "# Holonymous : The opposite of a meronym is a holonym - The name of the whole of which the meronym\n",
    "# Appletree is a holonym of apple \n",
    "\n",
    "from nltk.corpus import wordnet as wn\n",
    "wn.synset('bed.n.01').part_holonyms()\n",
    "\n",
    "wn.synset('bed.n.01').part_meronyms()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corpus_WordSimilarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word Similarity : Compute the similarity betwen words based on the distance between words in the wordNet network.\n",
    "# The Smaller the distance,the more similar the words\n",
    "\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "dog = wn.synset('dog.v.01')\n",
    "cat = wn.synset('cat.v.01')\n",
    "\n",
    "print(wn.path_similarity(dog,cat))\n",
    "\n",
    "phone = wn.synset('phone.v.01')\n",
    "\n",
    "print(wn.path_similarity(phone,dog))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Other Corpus data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['adventure',\n",
       " 'belles_lettres',\n",
       " 'editorial',\n",
       " 'fiction',\n",
       " 'government',\n",
       " 'hobbies',\n",
       " 'humor',\n",
       " 'learned',\n",
       " 'lore',\n",
       " 'mystery',\n",
       " 'news',\n",
       " 'religion',\n",
       " 'reviews',\n",
       " 'romance',\n",
       " 'science_fiction']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import corpus\n",
    "from nltk.corpus import brown\n",
    "\n",
    "# Get the categories in the corpus\n",
    "brown.categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the length of the categories\n",
    "len(brown.categories())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('There', 'EX'), ('were', 'BED'), ('thirty-eight', 'CD'), ('patients', 'NNS'), ('on', 'IN'), ('the', 'AT'), ('bus', 'NN'), ('the', 'AT'), ('morning', 'NN'), ('I', 'PPSS'), ('left', 'VBD'), ('for', 'IN'), ('Hanover', 'NP'), (',', ','), ('most', 'AP'), ('of', 'IN'), ('them', 'PPO'), ('disturbed', 'VBN'), ('and', 'CC'), ('hallucinating', 'VBG'), ('.', '.')], [('An', 'AT'), ('interne', 'NN'), (',', ','), ('a', 'AT'), ('nurse', 'NN'), ('and', 'CC'), ('two', 'CD'), ('attendants', 'NNS'), ('were', 'BED'), ('in', 'IN'), ('charge', 'NN'), ('of', 'IN'), ('us', 'PPO'), ('.', '.')], ...]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the Senetence code snippet where category is 'mystery'\n",
    "sentences = brown.sents(categories = 'mystery')\n",
    "\n",
    "# Get the POS tagged sentences\n",
    "brown.tagged_sents(categories = 'mystery')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['There were thirty-eight patients on the bus the morning I left for Hanover , most of them disturbed and hallucinating .',\n",
       " 'An interne , a nurse and two attendants were in charge of us .',\n",
       " \"I felt lonely and depressed as I stared out the bus window at Chicago's grim , dirty West Side .\",\n",
       " 'It seemed incredible , as I listened to the monotonous drone of voices and smelled the fetid odors coming from the patients , that technically I was a ward of the state of Illinois , going to a hospital for the mentally ill .',\n",
       " 'I suddenly thought of Mary Jane Brennan , the way her pretty eyes could flash with anger , her quiet competence , the gentleness and sweetness that lay just beneath the surface of her defenses .']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the Sentence in Natural Language\n",
    "sentences = [' '.join(sent_tokenize) for sent_tokenize in sentences]\n",
    "\n",
    "# Get first five sentences\n",
    "sentences[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('patients', 'NNS'),\n",
       " ('bus', 'NN'),\n",
       " ('morning', 'NN'),\n",
       " ('Hanover', 'NP'),\n",
       " ('interne', 'NN'),\n",
       " ('nurse', 'NN'),\n",
       " ('attendants', 'NNS'),\n",
       " ('charge', 'NN'),\n",
       " ('bus', 'NN'),\n",
       " ('window', 'NN')]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the Noun form tagged words\n",
    "taggedwords = brown.tagged_words(categories = 'mystery')\n",
    "\n",
    "nouns = [(word,tags) for word,tags in taggedwords if any(noun_tag in tags for noun_tag in ['NP','NN'])]\n",
    "\n",
    "nouns[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('man', 106),\n",
       " ('time', 82),\n",
       " ('door', 80),\n",
       " ('car', 69),\n",
       " ('room', 65),\n",
       " ('Mr.', 63),\n",
       " ('way', 61),\n",
       " ('office', 50),\n",
       " ('eyes', 48),\n",
       " ('hand', 46)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.probability import FreqDist\n",
    "\n",
    "# Get First 10 occuring Noun\n",
    "\n",
    "nouns_freq = FreqDist([word for word,tag in nouns])\n",
    "\n",
    "nouns_freq.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['YUGOSLAV', 'ECONOMY', 'WORSENED', 'IN', '1986', ',', 'BANK', 'DATA', 'SHOWS', 'National', 'Bank', 'economic', 'data', 'for', '1986', 'shows', 'that', 'Yugoslavia', \"'\", 's', 'trade', 'deficit', 'grew', ',', 'the', 'inflation', 'rate', 'rose', ',', 'wages', 'were', 'sharply', 'higher', ',', 'the', 'money', 'supply', 'expanded', 'and', 'the', 'value', 'of', 'the', 'dinar', 'fell', '.'], ['The', 'trade', 'deficit', 'for', '1986', 'was', '2', '.', '012', 'billion', 'dlrs', ',', '25', '.', '7', 'pct', 'higher', 'than', 'in', '1985', '.'], ...]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import reuters\n",
    "\n",
    "# get Sentenses\n",
    "sentences = reuters.sents(categories = ['housing','income'])\n",
    "\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test/16118',\n",
       " 'test/18534',\n",
       " 'test/18540',\n",
       " 'test/18664',\n",
       " 'test/18665',\n",
       " 'test/18672',\n",
       " 'test/18911',\n",
       " 'test/19875',\n",
       " 'test/20106',\n",
       " 'test/20116',\n",
       " 'training/1035',\n",
       " 'training/1036',\n",
       " 'training/10602',\n",
       " 'training/10604',\n",
       " 'training/11170',\n",
       " 'training/11665',\n",
       " 'training/2618',\n",
       " 'training/29',\n",
       " 'training/3105',\n",
       " 'training/3708',\n",
       " 'training/3720',\n",
       " 'training/3723',\n",
       " 'training/3898',\n",
       " 'training/5883',\n",
       " 'training/5886',\n",
       " 'training/6000',\n",
       " 'training/6067',\n",
       " 'training/6197',\n",
       " 'training/7005',\n",
       " 'training/7006',\n",
       " 'training/7015',\n",
       " 'training/7036',\n",
       " 'training/7098',\n",
       " 'training/7099',\n",
       " 'training/9615']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filed ID based access \n",
    "\n",
    "reuters.fileids(categories = ['housing','income'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['YUGOSLAV', 'ECONOMY', 'WORSENED', 'IN', '1986', ',', 'BANK', 'DATA', 'SHOWS', 'National', 'Bank', 'economic', 'data', 'for', '1986', 'shows', 'that', 'Yugoslavia', \"'\", 's', 'trade', 'deficit', 'grew', ',', 'the', 'inflation', 'rate', 'rose', ',', 'wages', 'were', 'sharply', 'higher', ',', 'the', 'money', 'supply', 'expanded', 'and', 'the', 'value', 'of', 'the', 'dinar', 'fell', '.'], ['The', 'trade', 'deficit', 'for', '1986', 'was', '2', '.', '012', 'billion', 'dlrs', ',', '25', '.', '7', 'pct', 'higher', 'than', 'in', '1985', '.'], ...]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reuters.sents(fileids = [u'test/16118',u'test/18534'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
